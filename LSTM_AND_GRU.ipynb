{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ussvarma/time_series_analysis/blob/main/LSTM_AND_GRU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sk5G7Pfi9r6L"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GRU,LSTM\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "Eq9GE8KJ9r6P",
        "outputId": "49d3896b-dcc5-474e-e107-dff8ed779477"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   Open         High          Low        Close    Adj Close\n",
              "Date                                                                       \n",
              "2004-08-19    49.813290    51.835709    47.800831    49.982655    49.982655\n",
              "2004-08-20    50.316402    54.336334    50.062355    53.952770    53.952770\n",
              "2004-08-23    55.168217    56.528118    54.321388    54.495735    54.495735\n",
              "2004-08-24    55.412300    55.591629    51.591621    52.239197    52.239197\n",
              "2004-08-25    52.284027    53.798351    51.746044    52.802086    52.802086\n",
              "...                 ...          ...          ...          ...          ...\n",
              "2022-05-23  2202.080078  2240.110107  2183.084961  2233.330078  2233.330078\n",
              "2022-05-24  2127.550049  2127.899902  2044.160034  2118.520020  2118.520020\n",
              "2022-05-25  2102.840088  2130.894043  2084.225098  2116.790039  2116.790039\n",
              "2022-05-26  2121.010010  2179.104980  2109.760010  2165.919922  2165.919922\n",
              "2022-05-27  2195.770020  2257.360107  2191.000000  2255.979980  2255.979980\n",
              "\n",
              "[4476 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f5cf6b38-b4b2-4df4-a203-97521cc94963\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2004-08-19</th>\n",
              "      <td>49.813290</td>\n",
              "      <td>51.835709</td>\n",
              "      <td>47.800831</td>\n",
              "      <td>49.982655</td>\n",
              "      <td>49.982655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2004-08-20</th>\n",
              "      <td>50.316402</td>\n",
              "      <td>54.336334</td>\n",
              "      <td>50.062355</td>\n",
              "      <td>53.952770</td>\n",
              "      <td>53.952770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2004-08-23</th>\n",
              "      <td>55.168217</td>\n",
              "      <td>56.528118</td>\n",
              "      <td>54.321388</td>\n",
              "      <td>54.495735</td>\n",
              "      <td>54.495735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2004-08-24</th>\n",
              "      <td>55.412300</td>\n",
              "      <td>55.591629</td>\n",
              "      <td>51.591621</td>\n",
              "      <td>52.239197</td>\n",
              "      <td>52.239197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2004-08-25</th>\n",
              "      <td>52.284027</td>\n",
              "      <td>53.798351</td>\n",
              "      <td>51.746044</td>\n",
              "      <td>52.802086</td>\n",
              "      <td>52.802086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-05-23</th>\n",
              "      <td>2202.080078</td>\n",
              "      <td>2240.110107</td>\n",
              "      <td>2183.084961</td>\n",
              "      <td>2233.330078</td>\n",
              "      <td>2233.330078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-05-24</th>\n",
              "      <td>2127.550049</td>\n",
              "      <td>2127.899902</td>\n",
              "      <td>2044.160034</td>\n",
              "      <td>2118.520020</td>\n",
              "      <td>2118.520020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-05-25</th>\n",
              "      <td>2102.840088</td>\n",
              "      <td>2130.894043</td>\n",
              "      <td>2084.225098</td>\n",
              "      <td>2116.790039</td>\n",
              "      <td>2116.790039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-05-26</th>\n",
              "      <td>2121.010010</td>\n",
              "      <td>2179.104980</td>\n",
              "      <td>2109.760010</td>\n",
              "      <td>2165.919922</td>\n",
              "      <td>2165.919922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-05-27</th>\n",
              "      <td>2195.770020</td>\n",
              "      <td>2257.360107</td>\n",
              "      <td>2191.000000</td>\n",
              "      <td>2255.979980</td>\n",
              "      <td>2255.979980</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4476 rows Ã— 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5cf6b38-b4b2-4df4-a203-97521cc94963')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f5cf6b38-b4b2-4df4-a203-97521cc94963 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f5cf6b38-b4b2-4df4-a203-97521cc94963');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "df=pd.read_csv(\"GOOG.csv\",parse_dates=[\"Date\"],index_col=[0])\n",
        "df=df.iloc[:,:-1]\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "P83ZVemM9r6Q",
        "outputId": "f1f0fbf1-cebd-4343-e4da-33c740c60601"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   Open         High          Low        Close    Adj Close\n",
              "Date                                                                       \n",
              "2022-05-23  2202.080078  2240.110107  2183.084961  2233.330078  2233.330078\n",
              "2022-05-24  2127.550049  2127.899902  2044.160034  2118.520020  2118.520020\n",
              "2022-05-25  2102.840088  2130.894043  2084.225098  2116.790039  2116.790039\n",
              "2022-05-26  2121.010010  2179.104980  2109.760010  2165.919922  2165.919922\n",
              "2022-05-27  2195.770020  2257.360107  2191.000000  2255.979980  2255.979980"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5c3bd87a-8a03-423e-afa7-37e8b482accb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-05-23</th>\n",
              "      <td>2202.080078</td>\n",
              "      <td>2240.110107</td>\n",
              "      <td>2183.084961</td>\n",
              "      <td>2233.330078</td>\n",
              "      <td>2233.330078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-05-24</th>\n",
              "      <td>2127.550049</td>\n",
              "      <td>2127.899902</td>\n",
              "      <td>2044.160034</td>\n",
              "      <td>2118.520020</td>\n",
              "      <td>2118.520020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-05-25</th>\n",
              "      <td>2102.840088</td>\n",
              "      <td>2130.894043</td>\n",
              "      <td>2084.225098</td>\n",
              "      <td>2116.790039</td>\n",
              "      <td>2116.790039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-05-26</th>\n",
              "      <td>2121.010010</td>\n",
              "      <td>2179.104980</td>\n",
              "      <td>2109.760010</td>\n",
              "      <td>2165.919922</td>\n",
              "      <td>2165.919922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-05-27</th>\n",
              "      <td>2195.770020</td>\n",
              "      <td>2257.360107</td>\n",
              "      <td>2191.000000</td>\n",
              "      <td>2255.979980</td>\n",
              "      <td>2255.979980</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c3bd87a-8a03-423e-afa7-37e8b482accb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5c3bd87a-8a03-423e-afa7-37e8b482accb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5c3bd87a-8a03-423e-afa7-37e8b482accb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eU88AehZ9r6R",
        "outputId": "8f393754-a366-429b-9e2d-9678d7fa7b78"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4476, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMu_wCtC9r6S",
        "outputId": "6b516fb3-c542-4995-b447-16cb9c7b29c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "895\n"
          ]
        }
      ],
      "source": [
        "test_split=round(len(df)*0.20)\n",
        "print(test_split)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4nNzdNz9r6S",
        "outputId": "94834c14-2cc7-48c4-8e9c-2b550164c5f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3581, 5)\n",
            "(895, 5)\n"
          ]
        }
      ],
      "source": [
        "df_for_training=df[:-895]\n",
        "df_for_testing=df[-895:]\n",
        "print(df_for_training.shape)\n",
        "print(df_for_testing.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTlceDWE9r6T",
        "outputId": "7fe951f1-0a4c-496e-97b8-389a7b12fd0d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.30298164e-04, 9.44785459e-04, 0.00000000e+00, 1.34908021e-04,\n",
              "        1.34908021e-04],\n",
              "       [7.42148227e-04, 2.98909923e-03, 1.88269054e-03, 3.39307537e-03,\n",
              "        3.39307537e-03],\n",
              "       [4.71386886e-03, 4.78092896e-03, 5.42828241e-03, 3.83867225e-03,\n",
              "        3.83867225e-03],\n",
              "       ...,\n",
              "       [8.38513750e-01, 8.43922922e-01, 8.38156069e-01, 8.27215513e-01,\n",
              "        8.27215513e-01],\n",
              "       [8.23181293e-01, 8.23889563e-01, 8.10375965e-01, 8.12689536e-01,\n",
              "        8.12689536e-01],\n",
              "       [8.10476525e-01, 8.28692499e-01, 8.24386693e-01, 8.25590596e-01,\n",
              "        8.25590596e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "df_for_training_scaled = scaler.fit_transform(df_for_training)\n",
        "df_for_testing_scaled=scaler.transform(df_for_testing)\n",
        "df_for_training_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6TicCgl9r6U"
      },
      "outputs": [],
      "source": [
        "def createXY(dataset,n_past):\n",
        "    dataX = []\n",
        "    dataY = []\n",
        "    for i in range(n_past, len(dataset)):\n",
        "            dataX.append(dataset[i - n_past:i, 0:dataset.shape[1]])\n",
        "            dataY.append(dataset[i,0])\n",
        "    return np.array(dataX),np.array(dataY)\n",
        "\n",
        "trainX,trainY=createXY(df_for_training_scaled,60)\n",
        "testX,testY=createXY(df_for_testing_scaled,60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gHJZaO49r6V",
        "outputId": "d5c6cbbb-ef15-4c18-d538-084cd3001819"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainX Shape--  (3521, 60, 5)\n",
            "trainY Shape--  (3521,)\n"
          ]
        }
      ],
      "source": [
        "print(\"trainX Shape-- \",trainX.shape)\n",
        "print(\"trainY Shape-- \",trainY.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2Mf4eMy9r6W",
        "outputId": "8326aaa6-d35a-4de4-f4e5-41dd0b677341"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainX[0]-- \n",
            " [[3.30298164e-04 9.44785459e-04 0.00000000e+00 1.34908021e-04\n",
            "  1.34908021e-04]\n",
            " [7.42148227e-04 2.98909923e-03 1.88269054e-03 3.39307537e-03\n",
            "  3.39307537e-03]\n",
            " [4.71386886e-03 4.78092896e-03 5.42828241e-03 3.83867225e-03\n",
            "  3.83867225e-03]\n",
            " [4.91367646e-03 4.01532941e-03 3.15578542e-03 1.98679178e-03\n",
            "  1.98679178e-03]\n",
            " [2.35285614e-03 2.54928676e-03 3.28434064e-03 2.44873974e-03\n",
            "  2.44873974e-03]\n",
            " [2.34877785e-03 2.52892558e-03 3.60779701e-03 3.22955376e-03\n",
            "  3.22955376e-03]\n",
            " [3.63326671e-03 2.80177162e-03 4.03492722e-03 2.51005881e-03\n",
            "  2.51005881e-03]\n",
            " [2.48334262e-03 1.52712947e-03 2.50886935e-03 8.17608079e-04\n",
            "  8.17608079e-04]\n",
            " [1.26817570e-03 8.02253103e-04 2.57107531e-03 9.64778600e-04\n",
            "  9.64778600e-04]\n",
            " [1.43128522e-03 5.00900100e-04 1.53849690e-03 9.81131336e-05\n",
            "  9.81131336e-05]\n",
            " [0.00000000e+00 2.56557750e-04 1.23577446e-03 6.13207085e-04\n",
            "  6.13207085e-04]\n",
            " [7.17681757e-04 0.00000000e+00 1.39335520e-03 0.00000000e+00\n",
            "  0.00000000e+00]\n",
            " [7.42148227e-04 1.05879614e-04 1.51361551e-03 6.41823963e-04\n",
            "  6.41823963e-04]\n",
            " [6.32050749e-04 5.25334172e-04 1.88269054e-03 9.36161722e-04\n",
            "  9.36161722e-04]\n",
            " [1.36196410e-03 3.95017216e-04 2.09003404e-03 9.40250316e-04\n",
            "  9.40250316e-04]\n",
            " [9.82732999e-04 1.96286905e-03 2.21444181e-03 2.17483839e-03\n",
            "  2.17483839e-03]\n",
            " [3.03383983e-03 2.71625319e-03 4.35423947e-03 3.06194683e-03\n",
            "  3.06194683e-03]\n",
            " [3.36821219e-03 4.17822295e-03 4.49108626e-03 4.69307521e-03\n",
            "  4.69307521e-03]\n",
            " [4.63639034e-03 5.08635485e-03 5.90517540e-03 4.90156480e-03\n",
            "  4.90156480e-03]\n",
            " [5.36222868e-03 5.72571360e-03 6.50647615e-03 5.70691038e-03\n",
            "  5.70691038e-03]\n",
            " [6.21040019e-03 6.41393804e-03 7.29438647e-03 7.14590027e-03\n",
            "  7.14590027e-03]\n",
            " [7.24206858e-03 8.08767275e-03 8.62968732e-03 7.91036647e-03\n",
            "  7.91036647e-03]\n",
            " [8.40830256e-03 7.60713465e-03 8.93655721e-03 7.28898220e-03\n",
            "  7.28898220e-03]\n",
            " [7.42556711e-03 7.30170876e-03 8.64627380e-03 7.50973757e-03\n",
            "  7.50973757e-03]\n",
            " [8.01276157e-03 8.50712404e-03 8.73335782e-03 8.50721918e-03\n",
            "  8.50721918e-03]\n",
            " [8.86908638e-03 9.10575715e-03 9.86960590e-03 8.10250168e-03\n",
            "  8.10250168e-03]\n",
            " [8.30635839e-03 7.79446226e-03 9.05681752e-03 7.46068100e-03\n",
            "  7.46068100e-03]\n",
            " [9.01588602e-03 1.04496286e-02 1.00562188e-02 1.09763986e-02\n",
            "  1.09763986e-02]\n",
            " [1.12178642e-02 1.35527557e-02 1.25526491e-02 1.27015524e-02\n",
            "  1.27015524e-02]\n",
            " [1.25227405e-02 1.24450743e-02 1.37013371e-02 1.20965225e-02\n",
            "  1.20965225e-02]\n",
            " [1.28897367e-02 1.32351079e-02 1.36598692e-02 1.33147594e-02\n",
            "  1.33147594e-02]\n",
            " [1.47043370e-02 1.43061333e-02 1.57872245e-02 1.43285913e-02\n",
            "  1.43285913e-02]\n",
            " [1.44637490e-02 1.49821456e-02 1.50449328e-02 1.56817330e-02\n",
            "  1.56817330e-02]\n",
            " [1.56422113e-02 1.49495682e-02 1.66041637e-02 1.51543807e-02\n",
            "  1.51543807e-02]\n",
            " [1.53853166e-02 1.55319098e-02 1.68322411e-02 1.58779610e-02\n",
            "  1.58779610e-02]\n",
            " [1.61193083e-02 1.54504651e-02 1.70271464e-02 1.54201008e-02\n",
            "  1.54201008e-02]\n",
            " [1.54179372e-02 1.51165322e-02 1.57125828e-02 1.44103575e-02\n",
            "  1.44103575e-02]\n",
            " [1.43740397e-02 1.46074896e-02 1.55259733e-02 1.52851968e-02\n",
            "  1.52851968e-02]\n",
            " [1.79950707e-02 1.70264594e-02 1.82960938e-02 1.67160087e-02\n",
            "  1.67160087e-02]\n",
            " [1.70531108e-02 1.65499942e-02 1.76657709e-02 1.71656975e-02\n",
            "  1.71656975e-02]\n",
            " [1.86515871e-02 1.78205667e-02 1.90715651e-02 1.80282711e-02\n",
            "  1.80282711e-02]\n",
            " [1.79461369e-02 1.93273342e-02 1.87646986e-02 2.00927330e-02\n",
            "  2.00927330e-02]\n",
            " [2.09228930e-02 2.06304833e-02 2.13108883e-02 1.95939942e-02\n",
            "  1.95939942e-02]\n",
            " [1.99156870e-02 1.92418166e-02 1.80970477e-02 1.65484018e-02\n",
            "  1.65484018e-02]\n",
            " [1.84354688e-02 1.97060631e-02 1.89347183e-02 2.01826698e-02\n",
            "  2.01826698e-02]\n",
            " [2.90946858e-02 3.19393716e-02 2.82486430e-02 2.96056110e-02\n",
            "  2.96056110e-02]\n",
            " [3.14842367e-02 3.77465332e-02 3.17610611e-02 3.57254103e-02\n",
            "  3.57254103e-02]\n",
            " [3.55375166e-02 3.70175872e-02 3.48504980e-02 3.34361069e-02\n",
            "  3.34361069e-02]\n",
            " [3.40613702e-02 3.57470147e-02 3.55845006e-02 3.51408234e-02\n",
            "  3.51408234e-02]\n",
            " [3.56761589e-02 3.77302425e-02 3.71727578e-02 3.81373584e-02\n",
            "  3.81373584e-02]\n",
            " [4.06550790e-02 3.99944670e-02 3.92462021e-02 3.70499376e-02\n",
            "  3.70499376e-02]\n",
            " [3.84775672e-02 3.90659739e-02 3.95240498e-02 3.92533937e-02\n",
            "  3.92533937e-02]\n",
            " [4.06102235e-02 3.97094022e-02 4.03824568e-02 3.87791799e-02\n",
            "  3.87791799e-02]\n",
            " [4.03655580e-02 4.06664064e-02 3.93084080e-02 3.74710062e-02\n",
            "  3.74710062e-02]\n",
            " [3.63938373e-02 3.61053792e-02 3.62397083e-02 3.46216408e-02\n",
            "  3.46216408e-02]\n",
            " [3.37596209e-02 3.28067844e-02 3.01023047e-02 2.83464946e-02\n",
            "  2.83464946e-02]\n",
            " [2.92537137e-02 3.00131586e-02 3.04547932e-02 2.96546675e-02\n",
            "  2.96546675e-02]\n",
            " [3.05463616e-02 2.99154223e-02 2.87421258e-02 2.80807737e-02\n",
            "  2.80807737e-02]\n",
            " [2.91476913e-02 2.88240316e-02 2.91816917e-02 2.77373761e-02\n",
            "  2.77373761e-02]\n",
            " [2.85197221e-02 3.33972717e-02 2.96959051e-02 3.39348522e-02\n",
            "  3.39348522e-02]]\n",
            "trainY[0]--  0.03508488283148054\n"
          ]
        }
      ],
      "source": [
        "print(\"trainX[0]-- \\n\",trainX[0])\n",
        "print(\"trainY[0]-- \",trainY[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxqMQOGY9r6X",
        "outputId": "a7ffdc74-9c8d-43a2-fcf0-14f170fa1947"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n"
          ]
        }
      ],
      "source": [
        "def build_model(optimizer,layers):\n",
        "    grid_model = Sequential()\n",
        "    grid_model.add(GRU(128,return_sequences=True,input_shape=(60,5)))\n",
        "    for i in range(layers):\n",
        "        if i == layers-1:\n",
        "            grid_model.add(GRU(128))\n",
        "        else:\n",
        "            grid_model.add(GRU(128, return_sequences=True))\n",
        "            grid_model.add(Dropout(0.2))\n",
        "            grid_model.add(LSTM(128, return_sequences=True))\n",
        "#     grid_model.add(GRU(50))\n",
        "     \n",
        "    grid_model.add(Dense(1))\n",
        "\n",
        "    grid_model.compile(loss = 'mse',optimizer = optimizer)\n",
        "    return grid_model\n",
        "\n",
        "grid_model = KerasRegressor(build_fn=build_model,verbose=1,validation_data=(testX,testY))\n",
        "parameters = {'batch_size' : [16,20],\n",
        "              'epochs' : [8,10],\n",
        "              'optimizer' : ['adam','Adadelta'],\n",
        "             \"layers\":[2,3,4]}\n",
        "\n",
        "grid_search  = GridSearchCV(estimator = grid_model,\n",
        "                            param_grid = parameters,\n",
        "                            cv = 2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hxQKzLl9r6Y",
        "outputId": "bc8adc2c-fc47-4465-8b36-306aa52c60ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "110/110 [==============================] - 7s 31ms/step - loss: 0.0061 - val_loss: 0.1230\n",
            "Epoch 2/8\n",
            "110/110 [==============================] - 2s 17ms/step - loss: 5.3072e-04 - val_loss: 0.0528\n",
            "Epoch 3/8\n",
            "110/110 [==============================] - 2s 17ms/step - loss: 5.3935e-04 - val_loss: 0.0678\n",
            "Epoch 4/8\n",
            "110/110 [==============================] - 2s 17ms/step - loss: 5.9994e-04 - val_loss: 0.0650\n",
            "Epoch 5/8\n",
            "110/110 [==============================] - 2s 17ms/step - loss: 3.2895e-04 - val_loss: 0.0676\n",
            "Epoch 6/8\n",
            "110/110 [==============================] - 2s 17ms/step - loss: 3.3204e-04 - val_loss: 0.0369\n",
            "Epoch 7/8\n",
            "110/110 [==============================] - 2s 17ms/step - loss: 4.0421e-04 - val_loss: 0.0323\n",
            "Epoch 8/8\n",
            "110/110 [==============================] - 2s 17ms/step - loss: 3.4674e-04 - val_loss: 0.0395\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 4.7454e-05\n",
            "Epoch 1/8\n",
            "111/111 [==============================] - 8s 29ms/step - loss: 9.0894e-04 - val_loss: 0.2211\n",
            "Epoch 2/8\n",
            "111/111 [==============================] - 2s 18ms/step - loss: 7.6334e-05 - val_loss: 0.1425\n",
            "Epoch 3/8\n",
            "111/111 [==============================] - 2s 18ms/step - loss: 7.6319e-05 - val_loss: 0.1930\n",
            "Epoch 4/8\n",
            "111/111 [==============================] - 2s 18ms/step - loss: 6.5256e-05 - val_loss: 0.1633\n",
            "Epoch 5/8\n",
            "111/111 [==============================] - 2s 18ms/step - loss: 5.3823e-05 - val_loss: 0.1778\n",
            "Epoch 6/8\n",
            "111/111 [==============================] - 2s 18ms/step - loss: 5.2633e-05 - val_loss: 0.1879\n",
            "Epoch 7/8\n",
            "111/111 [==============================] - 2s 18ms/step - loss: 4.7971e-05 - val_loss: 0.1649\n",
            "Epoch 8/8\n",
            "111/111 [==============================] - 2s 18ms/step - loss: 4.5150e-05 - val_loss: 0.1769\n",
            "110/110 [==============================] - 2s 7ms/step - loss: 0.0028\n",
            "Epoch 1/8\n",
            "110/110 [==============================] - 7s 28ms/step - loss: 0.2975 - val_loss: 2.3450\n",
            "Epoch 2/8\n",
            "110/110 [==============================] - 2s 17ms/step - loss: 0.2441 - val_loss: 2.0109\n",
            "Epoch 3/8\n",
            "110/110 [==============================] - 2s 17ms/step - loss: 0.1934 - val_loss: 1.6861\n",
            "Epoch 4/8\n",
            "110/110 [==============================] - 2s 17ms/step - loss: 0.1456 - val_loss: 1.3707\n",
            "Epoch 5/8\n",
            "110/110 [==============================] - 2s 17ms/step - loss: 0.1010 - val_loss: 1.0762\n",
            "Epoch 6/8\n",
            "110/110 [==============================] - 2s 17ms/step - loss: 0.0629 - val_loss: 0.8211\n",
            "Epoch 7/8\n",
            "110/110 [==============================] - 2s 17ms/step - loss: 0.0346 - val_loss: 0.6198\n",
            "Epoch 8/8\n",
            "110/110 [==============================] - 2s 17ms/step - loss: 0.0168 - val_loss: 0.4789\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.0021\n",
            "Epoch 1/8\n",
            "111/111 [==============================] - 9s 29ms/step - loss: 0.0223 - val_loss: 2.2988\n",
            "Epoch 2/8\n",
            "111/111 [==============================] - 2s 18ms/step - loss: 0.0185 - val_loss: 2.1472\n",
            "Epoch 3/8\n",
            "111/111 [==============================] - 3s 23ms/step - loss: 0.0151 - val_loss: 2.0070\n",
            "Epoch 4/8\n",
            "111/111 [==============================] - 3s 26ms/step - loss: 0.0121 - val_loss: 1.8784\n",
            "Epoch 5/8\n",
            "111/111 [==============================] - 2s 18ms/step - loss: 0.0096 - val_loss: 1.7626\n",
            "Epoch 6/8\n",
            "111/111 [==============================] - 2s 18ms/step - loss: 0.0074 - val_loss: 1.6581\n",
            "Epoch 7/8\n",
            "111/111 [==============================] - 2s 18ms/step - loss: 0.0056 - val_loss: 1.5657\n",
            "Epoch 8/8\n",
            "111/111 [==============================] - 2s 18ms/step - loss: 0.0043 - val_loss: 1.4865\n",
            "110/110 [==============================] - 2s 7ms/step - loss: 0.1329\n",
            "Epoch 1/8\n",
            "110/110 [==============================] - 10s 40ms/step - loss: 0.0069 - val_loss: 0.1370\n",
            "Epoch 2/8\n",
            "110/110 [==============================] - 3s 23ms/step - loss: 0.0010 - val_loss: 0.1569\n",
            "Epoch 3/8\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 8.0765e-04 - val_loss: 0.1078\n",
            "Epoch 4/8\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 8.2845e-04 - val_loss: 0.0912\n",
            "Epoch 5/8\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 6.5286e-04 - val_loss: 0.1011\n",
            "Epoch 6/8\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 6.9290e-04 - val_loss: 0.0978\n",
            "Epoch 7/8\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 7.7188e-04 - val_loss: 0.1214\n",
            "Epoch 8/8\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 8.5845e-04 - val_loss: 0.1258\n",
            "111/111 [==============================] - 1s 10ms/step - loss: 8.9849e-05\n",
            "Epoch 1/8\n",
            "111/111 [==============================] - 12s 43ms/step - loss: 4.7187e-04 - val_loss: 0.4012\n",
            "Epoch 2/8\n",
            "111/111 [==============================] - 3s 25ms/step - loss: 1.3128e-04 - val_loss: 0.3456\n",
            "Epoch 3/8\n",
            "111/111 [==============================] - 3s 25ms/step - loss: 1.3528e-04 - val_loss: 0.5343\n",
            "Epoch 4/8\n",
            "111/111 [==============================] - 3s 25ms/step - loss: 9.0717e-05 - val_loss: 0.4236\n",
            "Epoch 5/8\n",
            "111/111 [==============================] - 3s 25ms/step - loss: 9.0161e-05 - val_loss: 0.4465\n",
            "Epoch 6/8\n",
            "111/111 [==============================] - 3s 25ms/step - loss: 7.7523e-05 - val_loss: 0.3814\n",
            "Epoch 7/8\n",
            "111/111 [==============================] - 3s 25ms/step - loss: 7.7680e-05 - val_loss: 0.4455\n",
            "Epoch 8/8\n",
            "111/111 [==============================] - 3s 26ms/step - loss: 6.2584e-05 - val_loss: 0.3301\n",
            "110/110 [==============================] - 3s 10ms/step - loss: 0.0056\n",
            "Epoch 1/8\n",
            "110/110 [==============================] - 11s 40ms/step - loss: 0.2481 - val_loss: 2.0214\n",
            "Epoch 2/8\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 0.2013 - val_loss: 1.7263\n",
            "Epoch 3/8\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 0.1522 - val_loss: 1.4023\n",
            "Epoch 4/8\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 0.1005 - val_loss: 1.0630\n",
            "Epoch 5/8\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 0.0538 - val_loss: 0.7579\n",
            "Epoch 6/8\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 0.0222 - val_loss: 0.5443\n",
            "Epoch 7/8\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 0.0087 - val_loss: 0.4316\n",
            "Epoch 8/8\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 0.0051 - val_loss: 0.3797\n",
            "111/111 [==============================] - 1s 10ms/step - loss: 0.0070\n",
            "Epoch 1/8\n",
            "111/111 [==============================] - 12s 42ms/step - loss: 0.0214 - val_loss: 2.3265\n",
            "Epoch 2/8\n",
            "111/111 [==============================] - 3s 26ms/step - loss: 0.0182 - val_loss: 2.2327\n",
            "Epoch 3/8\n",
            "111/111 [==============================] - 3s 25ms/step - loss: 0.0152 - val_loss: 2.1419\n",
            "Epoch 4/8\n",
            "111/111 [==============================] - 3s 26ms/step - loss: 0.0124 - val_loss: 2.0549\n",
            "Epoch 5/8\n",
            "111/111 [==============================] - 3s 25ms/step - loss: 0.0099 - val_loss: 1.9736\n",
            "Epoch 6/8\n",
            "111/111 [==============================] - 3s 25ms/step - loss: 0.0078 - val_loss: 1.8973\n",
            "Epoch 7/8\n",
            "111/111 [==============================] - 3s 25ms/step - loss: 0.0060 - val_loss: 1.8277\n",
            "Epoch 8/8\n",
            "111/111 [==============================] - 3s 25ms/step - loss: 0.0046 - val_loss: 1.7651\n",
            "110/110 [==============================] - 3s 10ms/step - loss: 0.1558\n",
            "Epoch 1/8\n",
            "110/110 [==============================] - 14s 54ms/step - loss: 0.0069 - val_loss: 0.1797\n",
            "Epoch 2/8\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 0.0015 - val_loss: 0.2157\n",
            "Epoch 3/8\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 0.0011 - val_loss: 0.2228\n",
            "Epoch 4/8\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 9.8288e-04 - val_loss: 0.2161\n",
            "Epoch 5/8\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 0.0010 - val_loss: 0.2265\n",
            "Epoch 6/8\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 7.2773e-04 - val_loss: 0.2181\n",
            "Epoch 7/8\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 8.4973e-04 - val_loss: 0.2461\n",
            "Epoch 8/8\n",
            "110/110 [==============================] - 4s 32ms/step - loss: 7.1003e-04 - val_loss: 0.2162\n",
            "111/111 [==============================] - 1s 13ms/step - loss: 2.7127e-04\n",
            "Epoch 1/8\n",
            "111/111 [==============================] - 16s 54ms/step - loss: 0.0021 - val_loss: 0.8921\n",
            "Epoch 2/8\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 2.1903e-04 - val_loss: 0.8162\n",
            "Epoch 3/8\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 1.6217e-04 - val_loss: 0.7483\n",
            "Epoch 4/8\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 1.4207e-04 - val_loss: 0.7414\n",
            "Epoch 5/8\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 1.2921e-04 - val_loss: 0.5934\n",
            "Epoch 6/8\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 1.1138e-04 - val_loss: 0.7202\n",
            "Epoch 7/8\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 1.1451e-04 - val_loss: 0.5603\n",
            "Epoch 8/8\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 9.5920e-05 - val_loss: 0.5165\n",
            "110/110 [==============================] - 4s 13ms/step - loss: 0.0086\n",
            "Epoch 1/8\n",
            "110/110 [==============================] - 14s 52ms/step - loss: 0.2722 - val_loss: 2.2372\n",
            "Epoch 2/8\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 0.2416 - val_loss: 2.0542\n",
            "Epoch 3/8\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 0.2035 - val_loss: 1.8147\n",
            "Epoch 4/8\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 0.1532 - val_loss: 1.4958\n",
            "Epoch 5/8\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 0.0921 - val_loss: 1.1232\n",
            "Epoch 6/8\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 0.0395 - val_loss: 0.8157\n",
            "Epoch 7/8\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 0.0151 - val_loss: 0.6554\n",
            "Epoch 8/8\n",
            "110/110 [==============================] - 4s 32ms/step - loss: 0.0098 - val_loss: 0.5946\n",
            "111/111 [==============================] - 1s 13ms/step - loss: 0.0150\n",
            "Epoch 1/8\n",
            "111/111 [==============================] - 16s 54ms/step - loss: 0.0225 - val_loss: 2.4291\n",
            "Epoch 2/8\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0198 - val_loss: 2.3874\n",
            "Epoch 3/8\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0172 - val_loss: 2.3457\n",
            "Epoch 4/8\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0147 - val_loss: 2.3048\n",
            "Epoch 5/8\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0125 - val_loss: 2.2646\n",
            "Epoch 6/8\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0104 - val_loss: 2.2250\n",
            "Epoch 7/8\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0086 - val_loss: 2.1865\n",
            "Epoch 8/8\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0071 - val_loss: 2.1500\n",
            "110/110 [==============================] - 4s 13ms/step - loss: 0.2116\n",
            "Epoch 1/10\n",
            "110/110 [==============================] - 7s 28ms/step - loss: 0.0063 - val_loss: 0.0676\n",
            "Epoch 2/10\n",
            "110/110 [==============================] - 2s 17ms/step - loss: 5.1173e-04 - val_loss: 0.0783\n",
            "Epoch 3/10\n",
            "110/110 [==============================] - 2s 17ms/step - loss: 4.3737e-04 - val_loss: 0.0511\n",
            "Epoch 4/10\n",
            "110/110 [==============================] - 2s 17ms/step - loss: 4.2713e-04 - val_loss: 0.0493\n",
            "Epoch 5/10\n",
            "110/110 [==============================] - 2s 17ms/step - loss: 3.7740e-04 - val_loss: 0.0474\n",
            "Epoch 6/10\n",
            "110/110 [==============================] - 2s 17ms/step - loss: 4.2187e-04 - val_loss: 0.0301\n",
            "Epoch 7/10\n",
            "110/110 [==============================] - 2s 17ms/step - loss: 4.3215e-04 - val_loss: 0.0293\n",
            "Epoch 8/10\n",
            "110/110 [==============================] - 2s 17ms/step - loss: 4.5727e-04 - val_loss: 0.0553\n",
            "Epoch 9/10\n",
            "110/110 [==============================] - 2s 17ms/step - loss: 3.0275e-04 - val_loss: 0.0426\n",
            "Epoch 10/10\n",
            "110/110 [==============================] - 2s 17ms/step - loss: 2.1460e-04 - val_loss: 0.0203\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 4.5924e-05\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 8s 29ms/step - loss: 7.0918e-04 - val_loss: 0.2148\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 2s 18ms/step - loss: 8.3009e-05 - val_loss: 0.2293\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 2s 18ms/step - loss: 7.0773e-05 - val_loss: 0.1342\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 2s 18ms/step - loss: 7.5850e-05 - val_loss: 0.1632\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 3s 24ms/step - loss: 5.4836e-05 - val_loss: 0.1580\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 2s 18ms/step - loss: 5.0558e-05 - val_loss: 0.2499\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 2s 18ms/step - loss: 4.9284e-05 - val_loss: 0.1844\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 2s 18ms/step - loss: 3.6819e-05 - val_loss: 0.1788\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 2s 18ms/step - loss: 4.5586e-05 - val_loss: 0.1417\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 2s 18ms/step - loss: 3.1478e-05 - val_loss: 0.1640\n",
            "110/110 [==============================] - 2s 7ms/step - loss: 0.0024\n",
            "Epoch 1/10\n",
            "110/110 [==============================] - 7s 28ms/step - loss: 0.3251 - val_loss: 2.5180\n",
            "Epoch 2/10\n",
            "110/110 [==============================] - 2s 17ms/step - loss: 0.2663 - val_loss: 2.1385\n",
            "Epoch 3/10\n",
            "110/110 [==============================] - 2s 17ms/step - loss: 0.2108 - val_loss: 1.7727\n",
            "Epoch 4/10\n",
            "110/110 [==============================] - 2s 17ms/step - loss: 0.1584 - val_loss: 1.4220\n",
            "Epoch 5/10\n",
            "110/110 [==============================] - 2s 18ms/step - loss: 0.1094 - val_loss: 1.0984\n",
            "Epoch 6/10\n",
            "110/110 [==============================] - 2s 18ms/step - loss: 0.0675 - val_loss: 0.8202\n",
            "Epoch 7/10\n",
            "110/110 [==============================] - 2s 18ms/step - loss: 0.0367 - val_loss: 0.6040\n",
            "Epoch 8/10\n",
            "110/110 [==============================] - 2s 17ms/step - loss: 0.0171 - val_loss: 0.4562\n",
            "Epoch 9/10\n",
            "110/110 [==============================] - 2s 17ms/step - loss: 0.0077 - val_loss: 0.3634\n",
            "Epoch 10/10\n",
            "110/110 [==============================] - 2s 17ms/step - loss: 0.0043 - val_loss: 0.3118\n",
            "111/111 [==============================] - 1s 7ms/step - loss: 0.0056\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 8s 29ms/step - loss: 0.0235 - val_loss: 2.4135\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 2s 18ms/step - loss: 0.0196 - val_loss: 2.2585\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 2s 18ms/step - loss: 0.0161 - val_loss: 2.1154\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 2s 18ms/step - loss: 0.0130 - val_loss: 1.9840\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 2s 18ms/step - loss: 0.0103 - val_loss: 1.8647\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 2s 18ms/step - loss: 0.0081 - val_loss: 1.7577\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 2s 18ms/step - loss: 0.0062 - val_loss: 1.6619\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 2s 19ms/step - loss: 0.0048 - val_loss: 1.5775\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 2s 19ms/step - loss: 0.0036 - val_loss: 1.5036\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 2s 18ms/step - loss: 0.0028 - val_loss: 1.4420\n",
            "110/110 [==============================] - 2s 8ms/step - loss: 0.1194\n",
            "Epoch 1/10\n",
            "110/110 [==============================] - 11s 40ms/step - loss: 0.0089 - val_loss: 0.1191\n",
            "Epoch 2/10\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 8.0617e-04 - val_loss: 0.1133\n",
            "Epoch 3/10\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 8.0031e-04 - val_loss: 0.0955\n",
            "Epoch 4/10\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 8.5030e-04 - val_loss: 0.0982\n",
            "Epoch 5/10\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 5.8979e-04 - val_loss: 0.0991\n",
            "Epoch 6/10\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 5.5014e-04 - val_loss: 0.0816\n",
            "Epoch 7/10\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 7.2908e-04 - val_loss: 0.0986\n",
            "Epoch 8/10\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 6.5741e-04 - val_loss: 0.1001\n",
            "Epoch 9/10\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 5.8599e-04 - val_loss: 0.0875\n",
            "Epoch 10/10\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 4.3082e-04 - val_loss: 0.1003\n",
            "111/111 [==============================] - 1s 10ms/step - loss: 2.3946e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 12s 44ms/step - loss: 9.6245e-04 - val_loss: 0.5565\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 3s 26ms/step - loss: 1.4828e-04 - val_loss: 0.6049\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 3s 26ms/step - loss: 1.0482e-04 - val_loss: 0.5080\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 3s 26ms/step - loss: 1.2945e-04 - val_loss: 0.6151\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 3s 26ms/step - loss: 8.6054e-05 - val_loss: 0.3769\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 3s 26ms/step - loss: 6.8174e-05 - val_loss: 0.2749\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 3s 26ms/step - loss: 6.1926e-05 - val_loss: 0.2696\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 3s 26ms/step - loss: 5.5444e-05 - val_loss: 0.2590\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 3s 26ms/step - loss: 4.8336e-05 - val_loss: 0.2217\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 3s 26ms/step - loss: 5.0974e-05 - val_loss: 0.1875\n",
            "110/110 [==============================] - 3s 10ms/step - loss: 0.0010\n",
            "Epoch 1/10\n",
            "110/110 [==============================] - 11s 41ms/step - loss: 0.2791 - val_loss: 2.2647\n",
            "Epoch 2/10\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 0.2340 - val_loss: 1.9703\n",
            "Epoch 3/10\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 0.1848 - val_loss: 1.6365\n",
            "Epoch 4/10\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 0.1289 - val_loss: 1.2624\n",
            "Epoch 5/10\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 0.0732 - val_loss: 0.8984\n",
            "Epoch 6/10\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 0.0317 - val_loss: 0.6272\n",
            "Epoch 7/10\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 0.0116 - val_loss: 0.4784\n",
            "Epoch 8/10\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 0.0061 - val_loss: 0.4120\n",
            "Epoch 9/10\n",
            "110/110 [==============================] - 3s 24ms/step - loss: 0.0051 - val_loss: 0.3854\n",
            "Epoch 10/10\n",
            "110/110 [==============================] - 3s 25ms/step - loss: 0.0047 - val_loss: 0.3760\n",
            "111/111 [==============================] - 1s 10ms/step - loss: 0.0081\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 12s 42ms/step - loss: 0.0192 - val_loss: 2.2104\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 3s 26ms/step - loss: 0.0157 - val_loss: 2.1026\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 3s 26ms/step - loss: 0.0125 - val_loss: 2.0023\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 3s 26ms/step - loss: 0.0098 - val_loss: 1.9084\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 3s 26ms/step - loss: 0.0075 - val_loss: 1.8215\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 3s 26ms/step - loss: 0.0055 - val_loss: 1.7441\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 3s 26ms/step - loss: 0.0041 - val_loss: 1.6766\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 3s 25ms/step - loss: 0.0030 - val_loss: 1.6188\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 3s 25ms/step - loss: 0.0023 - val_loss: 1.5702\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 3s 26ms/step - loss: 0.0019 - val_loss: 1.5322\n",
            "110/110 [==============================] - 3s 10ms/step - loss: 0.1141\n",
            "Epoch 1/10\n",
            "110/110 [==============================] - 14s 54ms/step - loss: 0.0197 - val_loss: 0.2057\n",
            "Epoch 2/10\n",
            "110/110 [==============================] - 4s 33ms/step - loss: 9.9323e-04 - val_loss: 0.1711\n",
            "Epoch 3/10\n",
            "110/110 [==============================] - 4s 32ms/step - loss: 8.7066e-04 - val_loss: 0.1822\n",
            "Epoch 4/10\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 0.0011 - val_loss: 0.1994\n",
            "Epoch 5/10\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 7.9016e-04 - val_loss: 0.1744\n",
            "Epoch 6/10\n",
            "110/110 [==============================] - 4s 32ms/step - loss: 0.0011 - val_loss: 0.2017\n",
            "Epoch 7/10\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 0.0011 - val_loss: 0.2074\n",
            "Epoch 8/10\n",
            "110/110 [==============================] - 4s 32ms/step - loss: 0.0011 - val_loss: 0.1802\n",
            "Epoch 9/10\n",
            "110/110 [==============================] - 4s 32ms/step - loss: 6.9852e-04 - val_loss: 0.2339\n",
            "Epoch 10/10\n",
            "110/110 [==============================] - 4s 32ms/step - loss: 6.3493e-04 - val_loss: 0.1892\n",
            "111/111 [==============================] - 2s 14ms/step - loss: 4.7939e-04\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 17s 55ms/step - loss: 0.0019 - val_loss: 0.9087\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 2.2111e-04 - val_loss: 0.9584\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 1.9846e-04 - val_loss: 0.9585\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 1.3630e-04 - val_loss: 0.7456\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 1.2401e-04 - val_loss: 0.6371\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 1.2535e-04 - val_loss: 0.6259\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 1.1888e-04 - val_loss: 0.6323\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 9.2335e-05 - val_loss: 0.6590\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 8.6239e-05 - val_loss: 0.5696\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 8.2120e-05 - val_loss: 0.5983\n",
            "110/110 [==============================] - 4s 14ms/step - loss: 0.0137\n",
            "Epoch 1/10\n",
            "110/110 [==============================] - 14s 53ms/step - loss: 0.3067 - val_loss: 2.4575\n",
            "Epoch 2/10\n",
            "110/110 [==============================] - 4s 32ms/step - loss: 0.2769 - val_loss: 2.2829\n",
            "Epoch 3/10\n",
            "110/110 [==============================] - 4s 32ms/step - loss: 0.2425 - val_loss: 2.0645\n",
            "Epoch 4/10\n",
            "110/110 [==============================] - 4s 32ms/step - loss: 0.1978 - val_loss: 1.7619\n",
            "Epoch 5/10\n",
            "110/110 [==============================] - 4s 33ms/step - loss: 0.1364 - val_loss: 1.3493\n",
            "Epoch 6/10\n",
            "110/110 [==============================] - 4s 32ms/step - loss: 0.0666 - val_loss: 0.9215\n",
            "Epoch 7/10\n",
            "110/110 [==============================] - 4s 33ms/step - loss: 0.0222 - val_loss: 0.6662\n",
            "Epoch 8/10\n",
            "110/110 [==============================] - 4s 32ms/step - loss: 0.0104 - val_loss: 0.5741\n",
            "Epoch 9/10\n",
            "110/110 [==============================] - 4s 32ms/step - loss: 0.0089 - val_loss: 0.5448\n",
            "Epoch 10/10\n",
            "110/110 [==============================] - 4s 32ms/step - loss: 0.0083 - val_loss: 0.5292\n",
            "111/111 [==============================] - 1s 12ms/step - loss: 0.0156\n",
            "Epoch 1/10\n",
            "111/111 [==============================] - 16s 58ms/step - loss: 0.0226 - val_loss: 2.4833\n",
            "Epoch 2/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0195 - val_loss: 2.4306\n",
            "Epoch 3/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0167 - val_loss: 2.3788\n",
            "Epoch 4/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0140 - val_loss: 2.3292\n",
            "Epoch 5/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0116 - val_loss: 2.2808\n",
            "Epoch 6/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0094 - val_loss: 2.2332\n",
            "Epoch 7/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0076 - val_loss: 2.1892\n",
            "Epoch 8/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0061 - val_loss: 2.1475\n",
            "Epoch 9/10\n",
            "111/111 [==============================] - 4s 33ms/step - loss: 0.0049 - val_loss: 2.1087\n",
            "Epoch 10/10\n",
            "111/111 [==============================] - 4s 34ms/step - loss: 0.0039 - val_loss: 2.0739\n",
            "110/110 [==============================] - 4s 13ms/step - loss: 0.1857\n",
            "Epoch 1/8\n",
            "88/88 [==============================] - 6s 28ms/step - loss: 0.0093 - val_loss: 0.1064\n",
            "Epoch 2/8\n",
            "88/88 [==============================] - 1s 15ms/step - loss: 6.0851e-04 - val_loss: 0.0623\n",
            "Epoch 3/8\n",
            "88/88 [==============================] - 1s 15ms/step - loss: 4.8116e-04 - val_loss: 0.0768\n",
            "Epoch 4/8\n",
            "88/88 [==============================] - 1s 15ms/step - loss: 4.4155e-04 - val_loss: 0.0512\n",
            "Epoch 5/8\n",
            "88/88 [==============================] - 1s 15ms/step - loss: 3.5334e-04 - val_loss: 0.0420\n",
            "Epoch 6/8\n",
            "88/88 [==============================] - 1s 15ms/step - loss: 4.7553e-04 - val_loss: 0.0432\n",
            "Epoch 7/8\n",
            "88/88 [==============================] - 1s 15ms/step - loss: 3.8943e-04 - val_loss: 0.0513\n",
            "Epoch 8/8\n",
            "88/88 [==============================] - 1s 15ms/step - loss: 3.2650e-04 - val_loss: 0.0299\n",
            "89/89 [==============================] - 1s 7ms/step - loss: 5.0518e-05\n",
            "Epoch 1/8\n",
            "89/89 [==============================] - 8s 30ms/step - loss: 6.3935e-04 - val_loss: 0.2294\n",
            "Epoch 2/8\n",
            "89/89 [==============================] - 1s 17ms/step - loss: 7.5287e-05 - val_loss: 0.1776\n",
            "Epoch 3/8\n",
            "89/89 [==============================] - 1s 16ms/step - loss: 8.0927e-05 - val_loss: 0.1890\n",
            "Epoch 4/8\n",
            "89/89 [==============================] - 1s 16ms/step - loss: 5.9104e-05 - val_loss: 0.1459\n",
            "Epoch 5/8\n",
            "89/89 [==============================] - 1s 16ms/step - loss: 5.7571e-05 - val_loss: 0.1429\n",
            "Epoch 6/8\n",
            "89/89 [==============================] - 1s 16ms/step - loss: 7.7263e-05 - val_loss: 0.1815\n",
            "Epoch 7/8\n",
            "89/89 [==============================] - 1s 16ms/step - loss: 4.2997e-05 - val_loss: 0.1414\n",
            "Epoch 8/8\n",
            "89/89 [==============================] - 1s 16ms/step - loss: 4.0985e-05 - val_loss: 0.1651\n",
            "88/88 [==============================] - 2s 7ms/step - loss: 0.0021\n",
            "Epoch 1/8\n",
            "88/88 [==============================] - 7s 29ms/step - loss: 0.2591 - val_loss: 2.0877\n",
            "Epoch 2/8\n",
            "88/88 [==============================] - 1s 15ms/step - loss: 0.2075 - val_loss: 1.7604\n",
            "Epoch 3/8\n",
            "88/88 [==============================] - 1s 15ms/step - loss: 0.1590 - val_loss: 1.4498\n",
            "Epoch 4/8\n",
            "88/88 [==============================] - 1s 15ms/step - loss: 0.1152 - val_loss: 1.1612\n",
            "Epoch 5/8\n",
            "88/88 [==============================] - 1s 15ms/step - loss: 0.0762 - val_loss: 0.9071\n",
            "Epoch 6/8\n",
            "88/88 [==============================] - 1s 15ms/step - loss: 0.0459 - val_loss: 0.6971\n",
            "Epoch 7/8\n",
            "88/88 [==============================] - 1s 15ms/step - loss: 0.0247 - val_loss: 0.5385\n",
            "Epoch 8/8\n",
            "88/88 [==============================] - 1s 15ms/step - loss: 0.0122 - val_loss: 0.4263\n",
            "89/89 [==============================] - 1s 7ms/step - loss: 0.0018\n",
            "Epoch 1/8\n",
            "89/89 [==============================] - 8s 30ms/step - loss: 0.0159 - val_loss: 1.8664\n",
            "Epoch 2/8\n",
            "89/89 [==============================] - 1s 16ms/step - loss: 0.0133 - val_loss: 1.7620\n",
            "Epoch 3/8\n",
            "89/89 [==============================] - 1s 16ms/step - loss: 0.0110 - val_loss: 1.6646\n",
            "Epoch 4/8\n",
            "89/89 [==============================] - 1s 16ms/step - loss: 0.0091 - val_loss: 1.5748\n",
            "Epoch 5/8\n",
            "89/89 [==============================] - 1s 16ms/step - loss: 0.0073 - val_loss: 1.4926\n",
            "Epoch 6/8\n",
            "89/89 [==============================] - 1s 17ms/step - loss: 0.0058 - val_loss: 1.4190\n",
            "Epoch 7/8\n",
            "89/89 [==============================] - 1s 16ms/step - loss: 0.0045 - val_loss: 1.3523\n",
            "Epoch 8/8\n",
            "89/89 [==============================] - 1s 16ms/step - loss: 0.0035 - val_loss: 1.2936\n",
            "88/88 [==============================] - 2s 6ms/step - loss: 0.1044\n",
            "Epoch 1/8\n",
            "88/88 [==============================] - 10s 42ms/step - loss: 0.0119 - val_loss: 0.1393\n",
            "Epoch 2/8\n",
            "88/88 [==============================] - 2s 23ms/step - loss: 8.4459e-04 - val_loss: 0.1286\n",
            "Epoch 3/8\n",
            "88/88 [==============================] - 2s 22ms/step - loss: 8.1163e-04 - val_loss: 0.1078\n",
            "Epoch 4/8\n",
            "88/88 [==============================] - 2s 22ms/step - loss: 0.0011 - val_loss: 0.1673\n",
            "Epoch 5/8\n",
            "88/88 [==============================] - 2s 22ms/step - loss: 8.3535e-04 - val_loss: 0.1003\n",
            "Epoch 6/8\n",
            "88/88 [==============================] - 2s 22ms/step - loss: 8.4152e-04 - val_loss: 0.1204\n",
            "Epoch 7/8\n",
            "88/88 [==============================] - 2s 22ms/step - loss: 7.6317e-04 - val_loss: 0.1251\n",
            "Epoch 8/8\n",
            "88/88 [==============================] - 2s 22ms/step - loss: 6.8859e-04 - val_loss: 0.1060\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 1.2172e-04\n",
            "Epoch 1/8\n",
            "89/89 [==============================] - 11s 42ms/step - loss: 7.0278e-04 - val_loss: 0.4310\n",
            "Epoch 2/8\n",
            "89/89 [==============================] - 2s 23ms/step - loss: 1.2278e-04 - val_loss: 0.3815\n",
            "Epoch 3/8\n",
            "89/89 [==============================] - 2s 22ms/step - loss: 1.5024e-04 - val_loss: 0.4896\n",
            "Epoch 4/8\n",
            "89/89 [==============================] - 2s 24ms/step - loss: 1.1074e-04 - val_loss: 0.5310\n",
            "Epoch 5/8\n",
            "89/89 [==============================] - 2s 23ms/step - loss: 1.4133e-04 - val_loss: 0.5961\n",
            "Epoch 6/8\n",
            "89/89 [==============================] - 2s 23ms/step - loss: 9.4691e-05 - val_loss: 0.4414\n",
            "Epoch 7/8\n",
            "89/89 [==============================] - 2s 23ms/step - loss: 6.3383e-05 - val_loss: 0.4907\n",
            "Epoch 8/8\n",
            "89/89 [==============================] - 2s 23ms/step - loss: 6.1753e-05 - val_loss: 0.3885\n",
            "88/88 [==============================] - 3s 10ms/step - loss: 0.0070\n",
            "Epoch 1/8\n",
            "88/88 [==============================] - 10s 41ms/step - loss: 0.2845 - val_loss: 2.3266\n",
            "Epoch 2/8\n",
            "88/88 [==============================] - 2s 22ms/step - loss: 0.2539 - val_loss: 2.1311\n",
            "Epoch 3/8\n",
            "88/88 [==============================] - 2s 22ms/step - loss: 0.2215 - val_loss: 1.9213\n",
            "Epoch 4/8\n",
            "88/88 [==============================] - 2s 22ms/step - loss: 0.1863 - val_loss: 1.6871\n",
            "Epoch 5/8\n",
            "88/88 [==============================] - 2s 22ms/step - loss: 0.1475 - val_loss: 1.4260\n",
            "Epoch 6/8\n",
            "88/88 [==============================] - 2s 22ms/step - loss: 0.1057 - val_loss: 1.1502\n",
            "Epoch 7/8\n",
            "88/88 [==============================] - 2s 22ms/step - loss: 0.0663 - val_loss: 0.8892\n",
            "Epoch 8/8\n",
            "88/88 [==============================] - 2s 22ms/step - loss: 0.0354 - val_loss: 0.6797\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0030\n",
            "Epoch 1/8\n",
            "89/89 [==============================] - 11s 43ms/step - loss: 0.0201 - val_loss: 2.2158\n",
            "Epoch 2/8\n",
            "89/89 [==============================] - 2s 23ms/step - loss: 0.0178 - val_loss: 2.1586\n",
            "Epoch 3/8\n",
            "89/89 [==============================] - 2s 23ms/step - loss: 0.0157 - val_loss: 2.1027\n",
            "Epoch 4/8\n",
            "89/89 [==============================] - 2s 23ms/step - loss: 0.0137 - val_loss: 2.0472\n",
            "Epoch 5/8\n",
            "89/89 [==============================] - 2s 23ms/step - loss: 0.0118 - val_loss: 1.9936\n",
            "Epoch 6/8\n",
            "89/89 [==============================] - 2s 23ms/step - loss: 0.0101 - val_loss: 1.9417\n",
            "Epoch 7/8\n",
            "89/89 [==============================] - 2s 23ms/step - loss: 0.0085 - val_loss: 1.8920\n",
            "Epoch 8/8\n",
            "89/89 [==============================] - 2s 23ms/step - loss: 0.0071 - val_loss: 1.8440\n",
            "88/88 [==============================] - 2s 9ms/step - loss: 0.1765\n",
            "Epoch 1/8\n",
            "88/88 [==============================] - 13s 55ms/step - loss: 0.0135 - val_loss: 0.1747\n",
            "Epoch 2/8\n",
            "88/88 [==============================] - 2s 28ms/step - loss: 0.0012 - val_loss: 0.1469\n",
            "Epoch 3/8\n",
            "88/88 [==============================] - 2s 28ms/step - loss: 0.0011 - val_loss: 0.1785\n",
            "Epoch 4/8\n",
            "88/88 [==============================] - 2s 28ms/step - loss: 8.7077e-04 - val_loss: 0.1696\n",
            "Epoch 5/8\n",
            "88/88 [==============================] - 2s 28ms/step - loss: 0.0012 - val_loss: 0.1445\n",
            "Epoch 6/8\n",
            "88/88 [==============================] - 2s 28ms/step - loss: 8.9495e-04 - val_loss: 0.2170\n",
            "Epoch 7/8\n",
            "88/88 [==============================] - 2s 28ms/step - loss: 8.1766e-04 - val_loss: 0.1792\n",
            "Epoch 8/8\n",
            "88/88 [==============================] - 2s 27ms/step - loss: 8.4225e-04 - val_loss: 0.2111\n",
            "89/89 [==============================] - 1s 12ms/step - loss: 5.2376e-04\n",
            "Epoch 1/8\n",
            "89/89 [==============================] - 15s 56ms/step - loss: 0.0024 - val_loss: 0.8758\n",
            "Epoch 2/8\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 2.3937e-04 - val_loss: 0.8536\n",
            "Epoch 3/8\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 1.7778e-04 - val_loss: 0.9541\n",
            "Epoch 4/8\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 1.4972e-04 - val_loss: 0.6790\n",
            "Epoch 5/8\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 1.3362e-04 - val_loss: 0.6582\n",
            "Epoch 6/8\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 1.4008e-04 - val_loss: 0.7564\n",
            "Epoch 7/8\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 1.1720e-04 - val_loss: 0.6378\n",
            "Epoch 8/8\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 1.2233e-04 - val_loss: 0.6844\n",
            "88/88 [==============================] - 3s 13ms/step - loss: 0.0138\n",
            "Epoch 1/8\n",
            "88/88 [==============================] - 13s 58ms/step - loss: 0.2687 - val_loss: 2.2070\n",
            "Epoch 2/8\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 0.2402 - val_loss: 2.0319\n",
            "Epoch 3/8\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 0.2059 - val_loss: 1.8131\n",
            "Epoch 4/8\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 0.1627 - val_loss: 1.5342\n",
            "Epoch 5/8\n",
            "88/88 [==============================] - 2s 28ms/step - loss: 0.1103 - val_loss: 1.2029\n",
            "Epoch 6/8\n",
            "88/88 [==============================] - 2s 28ms/step - loss: 0.0580 - val_loss: 0.8855\n",
            "Epoch 7/8\n",
            "88/88 [==============================] - 3s 28ms/step - loss: 0.0237 - val_loss: 0.6702\n",
            "Epoch 8/8\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 0.0107 - val_loss: 0.5662\n",
            "89/89 [==============================] - 1s 12ms/step - loss: 0.0116\n",
            "Epoch 1/8\n",
            "89/89 [==============================] - 15s 59ms/step - loss: 0.0218 - val_loss: 2.3844\n",
            "Epoch 2/8\n",
            "89/89 [==============================] - 3s 33ms/step - loss: 0.0193 - val_loss: 2.3435\n",
            "Epoch 3/8\n",
            "89/89 [==============================] - 3s 33ms/step - loss: 0.0169 - val_loss: 2.3035\n",
            "Epoch 4/8\n",
            "89/89 [==============================] - 3s 32ms/step - loss: 0.0147 - val_loss: 2.2636\n",
            "Epoch 5/8\n",
            "89/89 [==============================] - 3s 32ms/step - loss: 0.0127 - val_loss: 2.2246\n",
            "Epoch 6/8\n",
            "89/89 [==============================] - 3s 32ms/step - loss: 0.0108 - val_loss: 2.1864\n",
            "Epoch 7/8\n",
            "89/89 [==============================] - 3s 31ms/step - loss: 0.0091 - val_loss: 2.1495\n",
            "Epoch 8/8\n",
            "89/89 [==============================] - 3s 32ms/step - loss: 0.0077 - val_loss: 2.1134\n",
            "88/88 [==============================] - 3s 13ms/step - loss: 0.2087\n",
            "Epoch 1/10\n",
            "88/88 [==============================] - 7s 30ms/step - loss: 0.0080 - val_loss: 0.0647\n",
            "Epoch 2/10\n",
            "88/88 [==============================] - 1s 16ms/step - loss: 4.5121e-04 - val_loss: 0.0404\n",
            "Epoch 3/10\n",
            "88/88 [==============================] - 1s 16ms/step - loss: 4.8273e-04 - val_loss: 0.0411\n",
            "Epoch 4/10\n",
            "88/88 [==============================] - 1s 15ms/step - loss: 4.0921e-04 - val_loss: 0.0442\n",
            "Epoch 5/10\n",
            "88/88 [==============================] - 1s 16ms/step - loss: 4.8420e-04 - val_loss: 0.0528\n",
            "Epoch 6/10\n",
            "88/88 [==============================] - 1s 16ms/step - loss: 4.1176e-04 - val_loss: 0.0739\n",
            "Epoch 7/10\n",
            "88/88 [==============================] - 1s 16ms/step - loss: 3.8819e-04 - val_loss: 0.0237\n",
            "Epoch 8/10\n",
            "88/88 [==============================] - 1s 16ms/step - loss: 3.2272e-04 - val_loss: 0.0330\n",
            "Epoch 9/10\n",
            "88/88 [==============================] - 1s 15ms/step - loss: 3.6010e-04 - val_loss: 0.0398\n",
            "Epoch 10/10\n",
            "88/88 [==============================] - 1s 16ms/step - loss: 4.1943e-04 - val_loss: 0.0325\n",
            "89/89 [==============================] - 1s 7ms/step - loss: 4.4864e-05\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 8s 31ms/step - loss: 6.6705e-04 - val_loss: 0.2096\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 1s 16ms/step - loss: 8.4370e-05 - val_loss: 0.0988\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 1s 17ms/step - loss: 8.2011e-05 - val_loss: 0.1510\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 2s 17ms/step - loss: 5.6716e-05 - val_loss: 0.1578\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 2s 17ms/step - loss: 7.3847e-05 - val_loss: 0.1929\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 1s 17ms/step - loss: 5.2654e-05 - val_loss: 0.1333\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 1s 17ms/step - loss: 4.4991e-05 - val_loss: 0.1452\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 1s 17ms/step - loss: 5.0037e-05 - val_loss: 0.0894\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 1s 17ms/step - loss: 3.9827e-05 - val_loss: 0.1088\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 1s 16ms/step - loss: 4.6499e-05 - val_loss: 0.1109\n",
            "88/88 [==============================] - 2s 7ms/step - loss: 9.9604e-04\n",
            "Epoch 1/10\n",
            "88/88 [==============================] - 7s 35ms/step - loss: 0.1903 - val_loss: 1.5885\n",
            "Epoch 2/10\n",
            "88/88 [==============================] - 1s 15ms/step - loss: 0.1477 - val_loss: 1.3098\n",
            "Epoch 3/10\n",
            "88/88 [==============================] - 1s 15ms/step - loss: 0.1090 - val_loss: 1.0550\n",
            "Epoch 4/10\n",
            "88/88 [==============================] - 1s 15ms/step - loss: 0.0756 - val_loss: 0.8290\n",
            "Epoch 5/10\n",
            "88/88 [==============================] - 1s 15ms/step - loss: 0.0481 - val_loss: 0.6387\n",
            "Epoch 6/10\n",
            "88/88 [==============================] - 1s 16ms/step - loss: 0.0277 - val_loss: 0.4892\n",
            "Epoch 7/10\n",
            "88/88 [==============================] - 1s 15ms/step - loss: 0.0143 - val_loss: 0.3796\n",
            "Epoch 8/10\n",
            "88/88 [==============================] - 1s 16ms/step - loss: 0.0070 - val_loss: 0.3052\n",
            "Epoch 9/10\n",
            "88/88 [==============================] - 1s 16ms/step - loss: 0.0037 - val_loss: 0.2576\n",
            "Epoch 10/10\n",
            "88/88 [==============================] - 1s 16ms/step - loss: 0.0023 - val_loss: 0.2308\n",
            "89/89 [==============================] - 1s 7ms/step - loss: 0.0028\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 7s 30ms/step - loss: 0.0252 - val_loss: 2.5904\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 1s 17ms/step - loss: 0.0220 - val_loss: 2.4637\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 1s 16ms/step - loss: 0.0190 - val_loss: 2.3442\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 2s 17ms/step - loss: 0.0163 - val_loss: 2.2311\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 2s 17ms/step - loss: 0.0139 - val_loss: 2.1253\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 1s 17ms/step - loss: 0.0117 - val_loss: 2.0253\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 2s 17ms/step - loss: 0.0097 - val_loss: 1.9336\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 1s 16ms/step - loss: 0.0080 - val_loss: 1.8488\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 1s 17ms/step - loss: 0.0065 - val_loss: 1.7712\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 2s 17ms/step - loss: 0.0053 - val_loss: 1.7005\n",
            "88/88 [==============================] - 2s 7ms/step - loss: 0.1552\n",
            "Epoch 1/10\n",
            "88/88 [==============================] - 10s 42ms/step - loss: 0.0083 - val_loss: 0.1385\n",
            "Epoch 2/10\n",
            "88/88 [==============================] - 2s 22ms/step - loss: 0.0012 - val_loss: 0.1788\n",
            "Epoch 3/10\n",
            "88/88 [==============================] - 2s 23ms/step - loss: 7.6419e-04 - val_loss: 0.1311\n",
            "Epoch 4/10\n",
            "88/88 [==============================] - 2s 23ms/step - loss: 6.6339e-04 - val_loss: 0.1116\n",
            "Epoch 5/10\n",
            "88/88 [==============================] - 2s 23ms/step - loss: 7.8821e-04 - val_loss: 0.1188\n",
            "Epoch 6/10\n",
            "88/88 [==============================] - 2s 23ms/step - loss: 6.4183e-04 - val_loss: 0.1195\n",
            "Epoch 7/10\n",
            "88/88 [==============================] - 2s 23ms/step - loss: 6.8486e-04 - val_loss: 0.1217\n",
            "Epoch 8/10\n",
            "88/88 [==============================] - 2s 23ms/step - loss: 5.5636e-04 - val_loss: 0.1013\n",
            "Epoch 9/10\n",
            "88/88 [==============================] - 2s 23ms/step - loss: 6.0135e-04 - val_loss: 0.1451\n",
            "Epoch 10/10\n",
            "88/88 [==============================] - 2s 23ms/step - loss: 6.5641e-04 - val_loss: 0.0992\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 1.6672e-04\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 11s 44ms/step - loss: 0.0016 - val_loss: 0.4374\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 2s 24ms/step - loss: 1.4972e-04 - val_loss: 0.4657\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 2s 24ms/step - loss: 1.3664e-04 - val_loss: 0.5021\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 2s 24ms/step - loss: 1.1449e-04 - val_loss: 0.4925\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 2s 24ms/step - loss: 8.7150e-05 - val_loss: 0.5645\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 2s 24ms/step - loss: 8.5593e-05 - val_loss: 0.3350\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 2s 23ms/step - loss: 8.2333e-05 - val_loss: 0.3833\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 2s 24ms/step - loss: 7.0947e-05 - val_loss: 0.3494\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 2s 24ms/step - loss: 6.7180e-05 - val_loss: 0.3703\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 2s 24ms/step - loss: 9.2525e-05 - val_loss: 0.3156\n",
            "88/88 [==============================] - 2s 9ms/step - loss: 0.0023\n",
            "Epoch 1/10\n",
            "88/88 [==============================] - 10s 43ms/step - loss: 0.2493 - val_loss: 2.0828\n",
            "Epoch 2/10\n",
            "88/88 [==============================] - 2s 23ms/step - loss: 0.2159 - val_loss: 1.8661\n",
            "Epoch 3/10\n",
            "88/88 [==============================] - 2s 23ms/step - loss: 0.1790 - val_loss: 1.6232\n",
            "Epoch 4/10\n",
            "88/88 [==============================] - 2s 23ms/step - loss: 0.1379 - val_loss: 1.3554\n",
            "Epoch 5/10\n",
            "88/88 [==============================] - 2s 23ms/step - loss: 0.0954 - val_loss: 1.0793\n",
            "Epoch 6/10\n",
            "88/88 [==============================] - 2s 23ms/step - loss: 0.0566 - val_loss: 0.8276\n",
            "Epoch 7/10\n",
            "88/88 [==============================] - 2s 23ms/step - loss: 0.0280 - val_loss: 0.6349\n",
            "Epoch 8/10\n",
            "88/88 [==============================] - 2s 22ms/step - loss: 0.0128 - val_loss: 0.5109\n",
            "Epoch 9/10\n",
            "88/88 [==============================] - 2s 23ms/step - loss: 0.0068 - val_loss: 0.4419\n",
            "Epoch 10/10\n",
            "88/88 [==============================] - 2s 23ms/step - loss: 0.0051 - val_loss: 0.4077\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0075\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 11s 44ms/step - loss: 0.0230 - val_loss: 2.4972\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 2s 24ms/step - loss: 0.0199 - val_loss: 2.4123\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 2s 24ms/step - loss: 0.0171 - val_loss: 2.3312\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 2s 24ms/step - loss: 0.0145 - val_loss: 2.2532\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 2s 24ms/step - loss: 0.0122 - val_loss: 2.1790\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 2s 24ms/step - loss: 0.0101 - val_loss: 2.1081\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 2s 25ms/step - loss: 0.0082 - val_loss: 2.0414\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 2s 24ms/step - loss: 0.0067 - val_loss: 1.9803\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 2s 24ms/step - loss: 0.0053 - val_loss: 1.9236\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 2s 24ms/step - loss: 0.0043 - val_loss: 1.8721\n",
            "88/88 [==============================] - 3s 11ms/step - loss: 0.1655\n",
            "Epoch 1/10\n",
            "88/88 [==============================] - 13s 64ms/step - loss: 0.0190 - val_loss: 0.1763\n",
            "Epoch 2/10\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 0.0012 - val_loss: 0.1754\n",
            "Epoch 3/10\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 9.4464e-04 - val_loss: 0.1938\n",
            "Epoch 4/10\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 8.8571e-04 - val_loss: 0.1695\n",
            "Epoch 5/10\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 8.6959e-04 - val_loss: 0.1955\n",
            "Epoch 6/10\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 0.0010 - val_loss: 0.2423\n",
            "Epoch 7/10\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 8.8763e-04 - val_loss: 0.1868\n",
            "Epoch 8/10\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 7.6525e-04 - val_loss: 0.1975\n",
            "Epoch 9/10\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 8.2274e-04 - val_loss: 0.1931\n",
            "Epoch 10/10\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 7.4214e-04 - val_loss: 0.1916\n",
            "89/89 [==============================] - 1s 12ms/step - loss: 1.4190e-04\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 15s 57ms/step - loss: 0.0016 - val_loss: 0.9469\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 3s 30ms/step - loss: 1.8603e-04 - val_loss: 0.8845\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 3s 32ms/step - loss: 1.7835e-04 - val_loss: 0.7892\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 3s 32ms/step - loss: 1.4257e-04 - val_loss: 0.8676\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 3s 31ms/step - loss: 1.2147e-04 - val_loss: 0.6155\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 3s 32ms/step - loss: 1.0812e-04 - val_loss: 0.4337\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 3s 31ms/step - loss: 1.1717e-04 - val_loss: 0.4427\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 3s 31ms/step - loss: 8.7106e-05 - val_loss: 0.3953\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 3s 31ms/step - loss: 1.0018e-04 - val_loss: 0.4873\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 3s 32ms/step - loss: 7.6917e-05 - val_loss: 0.4404\n",
            "88/88 [==============================] - 3s 13ms/step - loss: 0.0056\n",
            "Epoch 1/10\n",
            "88/88 [==============================] - 13s 58ms/step - loss: 0.2968 - val_loss: 2.4348\n",
            "Epoch 2/10\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 0.2785 - val_loss: 2.3308\n",
            "Epoch 3/10\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 0.2591 - val_loss: 2.2128\n",
            "Epoch 4/10\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 0.2361 - val_loss: 2.0663\n",
            "Epoch 5/10\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 0.2070 - val_loss: 1.8731\n",
            "Epoch 6/10\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 0.1683 - val_loss: 1.6132\n",
            "Epoch 7/10\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 0.1186 - val_loss: 1.2871\n",
            "Epoch 8/10\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 0.0659 - val_loss: 0.9571\n",
            "Epoch 9/10\n",
            "88/88 [==============================] - 3s 29ms/step - loss: 0.0286 - val_loss: 0.7250\n",
            "Epoch 10/10\n",
            "88/88 [==============================] - 3s 30ms/step - loss: 0.0139 - val_loss: 0.6118\n",
            "89/89 [==============================] - 1s 12ms/step - loss: 0.0176\n",
            "Epoch 1/10\n",
            "89/89 [==============================] - 15s 59ms/step - loss: 0.0231 - val_loss: 2.5027\n",
            "Epoch 2/10\n",
            "89/89 [==============================] - 3s 31ms/step - loss: 0.0209 - val_loss: 2.4665\n",
            "Epoch 3/10\n",
            "89/89 [==============================] - 3s 32ms/step - loss: 0.0188 - val_loss: 2.4305\n",
            "Epoch 4/10\n",
            "89/89 [==============================] - 3s 32ms/step - loss: 0.0168 - val_loss: 2.3951\n",
            "Epoch 5/10\n",
            "89/89 [==============================] - 3s 33ms/step - loss: 0.0148 - val_loss: 2.3595\n",
            "Epoch 6/10\n",
            "89/89 [==============================] - 3s 33ms/step - loss: 0.0130 - val_loss: 2.3244\n",
            "Epoch 7/10\n",
            "89/89 [==============================] - 3s 38ms/step - loss: 0.0113 - val_loss: 2.2900\n",
            "Epoch 8/10\n",
            "89/89 [==============================] - 3s 32ms/step - loss: 0.0097 - val_loss: 2.2564\n",
            "Epoch 9/10\n",
            "89/89 [==============================] - 3s 32ms/step - loss: 0.0083 - val_loss: 2.2239\n",
            "Epoch 10/10\n",
            "89/89 [==============================] - 3s 32ms/step - loss: 0.0071 - val_loss: 2.1921\n",
            "88/88 [==============================] - 4s 14ms/step - loss: 0.2126\n",
            "Epoch 1/10\n",
            "177/177 [==============================] - 8s 22ms/step - loss: 0.0024 - val_loss: 0.1051\n",
            "Epoch 2/10\n",
            "177/177 [==============================] - 3s 16ms/step - loss: 4.2544e-04 - val_loss: 0.1007\n",
            "Epoch 3/10\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 3.6947e-04 - val_loss: 0.0703\n",
            "Epoch 4/10\n",
            "177/177 [==============================] - 3s 16ms/step - loss: 2.6627e-04 - val_loss: 0.0396\n",
            "Epoch 5/10\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 2.2926e-04 - val_loss: 0.0540\n",
            "Epoch 6/10\n",
            "177/177 [==============================] - 3s 16ms/step - loss: 2.4535e-04 - val_loss: 0.0462\n",
            "Epoch 7/10\n",
            "177/177 [==============================] - 3s 15ms/step - loss: 1.6046e-04 - val_loss: 0.0479\n",
            "Epoch 8/10\n",
            "177/177 [==============================] - 3s 16ms/step - loss: 1.6809e-04 - val_loss: 0.0512\n",
            "Epoch 9/10\n",
            "177/177 [==============================] - 3s 16ms/step - loss: 2.4572e-04 - val_loss: 0.0426\n",
            "Epoch 10/10\n",
            "177/177 [==============================] - 3s 16ms/step - loss: 2.5712e-04 - val_loss: 0.0278\n"
          ]
        }
      ],
      "source": [
        "grid_search = grid_search.fit(trainX,trainY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtWXSb3X9r6Z"
      },
      "outputs": [],
      "source": [
        "my_model=grid_search.best_estimator_.model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBgdnRvH9r6Z"
      },
      "outputs": [],
      "source": [
        "prediction=my_model.predict(testX)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkWV-7nP9r6Z",
        "outputId": "7484e97b-4559-49c1-d189-28162b06abbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction\n",
            " [[0.89352775]\n",
            " [0.8928763 ]\n",
            " [0.8843836 ]\n",
            " [0.8782012 ]\n",
            " [0.87637454]\n",
            " [0.8826229 ]\n",
            " [0.88806134]\n",
            " [0.890081  ]\n",
            " [0.89001477]\n",
            " [0.88986903]\n",
            " [0.8890703 ]\n",
            " [0.88384444]\n",
            " [0.88310874]\n",
            " [0.8845107 ]\n",
            " [0.8856408 ]\n",
            " [0.8863172 ]\n",
            " [0.88861835]\n",
            " [0.8960071 ]\n",
            " [0.90333366]\n",
            " [0.91157854]\n",
            " [0.9164195 ]\n",
            " [0.91417897]\n",
            " [0.9104456 ]\n",
            " [0.9181872 ]\n",
            " [0.9309561 ]\n",
            " [0.93978643]\n",
            " [0.9420836 ]\n",
            " [0.94285154]\n",
            " [0.9425722 ]\n",
            " [0.9465972 ]\n",
            " [0.9561005 ]\n",
            " [0.96484274]\n",
            " [0.9640293 ]\n",
            " [0.9579649 ]\n",
            " [0.9524726 ]\n",
            " [0.94533235]\n",
            " [0.93950665]\n",
            " [0.9381368 ]\n",
            " [0.94398177]\n",
            " [0.9492659 ]\n",
            " [0.95492697]\n",
            " [0.9599188 ]\n",
            " [0.9614312 ]\n",
            " [0.9606581 ]\n",
            " [0.9579246 ]\n",
            " [0.9579102 ]\n",
            " [0.95915085]\n",
            " [0.9635837 ]\n",
            " [0.96723455]\n",
            " [0.9715234 ]\n",
            " [0.97692615]\n",
            " [0.980659  ]\n",
            " [0.9848131 ]\n",
            " [0.99273443]\n",
            " [0.9965504 ]\n",
            " [0.99976224]\n",
            " [1.0043176 ]\n",
            " [1.0112346 ]\n",
            " [0.9823994 ]\n",
            " [0.96135485]\n",
            " [0.94824684]\n",
            " [0.9473533 ]\n",
            " [0.9475204 ]\n",
            " [0.94415104]\n",
            " [0.9400264 ]\n",
            " [0.93504095]\n",
            " [0.93209636]\n",
            " [0.9211244 ]\n",
            " [0.9117255 ]\n",
            " [0.91541773]\n",
            " [0.9259689 ]\n",
            " [0.9281367 ]\n",
            " [0.9199965 ]\n",
            " [0.9179701 ]\n",
            " [0.9185222 ]\n",
            " [0.91489184]\n",
            " [0.91166466]\n",
            " [0.90988475]\n",
            " [0.90269464]\n",
            " [0.89820546]\n",
            " [0.8914603 ]\n",
            " [0.86676884]\n",
            " [0.8541279 ]\n",
            " [0.8460377 ]\n",
            " [0.8414302 ]\n",
            " [0.8447872 ]\n",
            " [0.8527199 ]\n",
            " [0.8581487 ]\n",
            " [0.8583167 ]\n",
            " [0.86176914]\n",
            " [0.8634432 ]\n",
            " [0.86620426]\n",
            " [0.87226003]\n",
            " [0.87468785]\n",
            " [0.87923324]\n",
            " [0.88409406]\n",
            " [0.88608783]\n",
            " [0.87926424]\n",
            " [0.8713465 ]\n",
            " [0.86637   ]\n",
            " [0.8642163 ]\n",
            " [0.8694593 ]\n",
            " [0.87583613]\n",
            " [0.88328725]\n",
            " [0.8897445 ]\n",
            " [0.8899454 ]\n",
            " [0.8907735 ]\n",
            " [0.897286  ]\n",
            " [0.9035175 ]\n",
            " [0.9067546 ]\n",
            " [0.909769  ]\n",
            " [0.9129052 ]\n",
            " [0.91363144]\n",
            " [0.9123761 ]\n",
            " [0.908778  ]\n",
            " [0.9070277 ]\n",
            " [0.90898275]\n",
            " [0.9078589 ]\n",
            " [0.90559214]\n",
            " [0.94217575]\n",
            " [0.9618705 ]\n",
            " [0.9667025 ]\n",
            " [0.96649754]\n",
            " [0.96497005]\n",
            " [0.95898265]\n",
            " [0.9422013 ]\n",
            " [0.9376156 ]\n",
            " [0.93587506]\n",
            " [0.94417775]\n",
            " [0.94693583]\n",
            " [0.9428947 ]\n",
            " [0.9456301 ]\n",
            " [0.93966776]\n",
            " [0.9359632 ]\n",
            " [0.9377419 ]\n",
            " [0.94555175]\n",
            " [0.9459815 ]\n",
            " [0.9477738 ]\n",
            " [0.9480101 ]\n",
            " [0.9380084 ]\n",
            " [0.93404067]\n",
            " [0.9341698 ]\n",
            " [0.93382144]\n",
            " [0.94071454]\n",
            " [0.9446985 ]\n",
            " [0.94011134]\n",
            " [0.94012886]\n",
            " [0.94950473]\n",
            " [0.9549227 ]\n",
            " [0.9568983 ]\n",
            " [0.9576043 ]\n",
            " [0.96216995]\n",
            " [0.97058195]\n",
            " [0.97674024]\n",
            " [0.97812057]\n",
            " [0.9781642 ]\n",
            " [0.9784456 ]\n",
            " [0.9815978 ]\n",
            " [0.98121643]\n",
            " [0.98134595]\n",
            " [0.97845244]\n",
            " [0.9813957 ]\n",
            " [0.98452914]\n",
            " [0.98184437]\n",
            " [0.977413  ]\n",
            " [0.9721048 ]\n",
            " [0.959424  ]\n",
            " [0.9528861 ]\n",
            " [0.956982  ]\n",
            " [0.9609575 ]\n",
            " [0.95740426]\n",
            " [0.95830756]\n",
            " [0.96054083]\n",
            " [0.9653994 ]\n",
            " [0.96784973]\n",
            " [0.9756814 ]\n",
            " [0.98245484]\n",
            " [0.9893409 ]\n",
            " [0.99089396]\n",
            " [0.9914947 ]\n",
            " [0.9911832 ]\n",
            " [0.99465257]\n",
            " [0.9986502 ]\n",
            " [1.0012798 ]\n",
            " [1.0111414 ]\n",
            " [1.0094845 ]\n",
            " [1.006324  ]\n",
            " [1.004926  ]\n",
            " [1.0081992 ]\n",
            " [1.0158975 ]\n",
            " [1.0219456 ]\n",
            " [1.024036  ]\n",
            " [1.0307041 ]\n",
            " [1.0358123 ]\n",
            " [1.035048  ]\n",
            " [1.0345768 ]\n",
            " [1.0338868 ]\n",
            " [1.0370853 ]\n",
            " [1.0462697 ]\n",
            " [1.0490352 ]\n",
            " [1.0484499 ]\n",
            " [1.043274  ]\n",
            " [1.0400474 ]\n",
            " [1.0373932 ]\n",
            " [1.0387026 ]\n",
            " [1.041828  ]\n",
            " [1.0439321 ]\n",
            " [1.0423684 ]\n",
            " [1.0364869 ]\n",
            " [1.0332395 ]\n",
            " [1.0405947 ]\n",
            " [1.047777  ]\n",
            " [1.0556873 ]\n",
            " [1.0615028 ]\n",
            " [1.0642213 ]\n",
            " [1.0666023 ]\n",
            " [1.0690023 ]\n",
            " [1.0700747 ]\n",
            " [1.0748099 ]\n",
            " [1.0763651 ]\n",
            " [1.0762236 ]\n",
            " [1.0766033 ]\n",
            " [1.0762959 ]\n",
            " [1.0754955 ]\n",
            " [1.0732158 ]\n",
            " [1.0759546 ]\n",
            " [1.0768121 ]\n",
            " [1.0720198 ]\n",
            " [1.0680386 ]\n",
            " [1.0747206 ]\n",
            " [1.0776018 ]\n",
            " [1.0866991 ]\n",
            " [1.0959374 ]\n",
            " [1.1031036 ]\n",
            " [1.112789  ]\n",
            " [1.1210034 ]\n",
            " [1.1281769 ]\n",
            " [1.1306752 ]\n",
            " [1.1337101 ]\n",
            " [1.1398757 ]\n",
            " [1.151939  ]\n",
            " [1.160711  ]\n",
            " [1.1672815 ]\n",
            " [1.1703544 ]\n",
            " [1.1671346 ]\n",
            " [1.1516505 ]\n",
            " [1.1500845 ]\n",
            " [1.1531318 ]\n",
            " [1.1521595 ]\n",
            " [1.1480176 ]\n",
            " [1.1592134 ]\n",
            " [1.1536102 ]\n",
            " [1.1508319 ]\n",
            " [1.1573559 ]\n",
            " [1.1631875 ]\n",
            " [1.1735777 ]\n",
            " [1.1829439 ]\n",
            " [1.1893235 ]\n",
            " [1.1917611 ]\n",
            " [1.1944178 ]\n",
            " [1.1966673 ]\n",
            " [1.2003927 ]\n",
            " [1.1993804 ]\n",
            " [1.1891929 ]\n",
            " [1.1609281 ]\n",
            " [1.1389202 ]\n",
            " [1.1270921 ]\n",
            " [1.0987179 ]\n",
            " [1.0803082 ]\n",
            " [1.0890942 ]\n",
            " [1.0867366 ]\n",
            " [1.0916775 ]\n",
            " [1.0763872 ]\n",
            " [1.0560111 ]\n",
            " [1.020626  ]\n",
            " [1.0182127 ]\n",
            " [1.0023656 ]\n",
            " [0.9606386 ]\n",
            " [0.95961726]\n",
            " [0.92655516]\n",
            " [0.910061  ]\n",
            " [0.893953  ]\n",
            " [0.89227885]\n",
            " [0.8845751 ]\n",
            " [0.8672288 ]\n",
            " [0.8801863 ]\n",
            " [0.8842984 ]\n",
            " [0.8969429 ]\n",
            " [0.89499694]\n",
            " [0.8990672 ]\n",
            " [0.9094082 ]\n",
            " [0.89909315]\n",
            " [0.8940575 ]\n",
            " [0.887093  ]\n",
            " [0.90685207]\n",
            " [0.92661524]\n",
            " [0.9411265 ]\n",
            " [0.95041037]\n",
            " [0.95537955]\n",
            " [0.9754922 ]\n",
            " [0.98614925]\n",
            " [0.9925828 ]\n",
            " [1.0033288 ]\n",
            " [1.0048184 ]\n",
            " [0.9902566 ]\n",
            " [0.9951626 ]\n",
            " [1.0045861 ]\n",
            " [1.0080196 ]\n",
            " [1.012074  ]\n",
            " [1.0031465 ]\n",
            " [1.0307047 ]\n",
            " [1.0470942 ]\n",
            " [1.0482416 ]\n",
            " [1.0475674 ]\n",
            " [1.0583353 ]\n",
            " [1.065215  ]\n",
            " [1.074617  ]\n",
            " [1.0857878 ]\n",
            " [1.0953768 ]\n",
            " [1.0955431 ]\n",
            " [1.0850022 ]\n",
            " [1.0783672 ]\n",
            " [1.0813667 ]\n",
            " [1.0875945 ]\n",
            " [1.090779  ]\n",
            " [1.1008627 ]\n",
            " [1.1065834 ]\n",
            " [1.1102549 ]\n",
            " [1.1175829 ]\n",
            " [1.118681  ]\n",
            " [1.1194524 ]\n",
            " [1.1241925 ]\n",
            " [1.1280667 ]\n",
            " [1.1320219 ]\n",
            " [1.1348889 ]\n",
            " [1.1292574 ]\n",
            " [1.1314741 ]\n",
            " [1.1361754 ]\n",
            " [1.1435866 ]\n",
            " [1.1509341 ]\n",
            " [1.1367857 ]\n",
            " [1.1290921 ]\n",
            " [1.1256758 ]\n",
            " [1.1344832 ]\n",
            " [1.1413214 ]\n",
            " [1.1406201 ]\n",
            " [1.138684  ]\n",
            " [1.1418225 ]\n",
            " [1.1494465 ]\n",
            " [1.1457489 ]\n",
            " [1.1424785 ]\n",
            " [1.119624  ]\n",
            " [1.1106206 ]\n",
            " [1.1151851 ]\n",
            " [1.1259266 ]\n",
            " [1.1416607 ]\n",
            " [1.1593064 ]\n",
            " [1.1671504 ]\n",
            " [1.1729887 ]\n",
            " [1.1805264 ]\n",
            " [1.1921136 ]\n",
            " [1.195199  ]\n",
            " [1.1929293 ]\n",
            " [1.1935518 ]\n",
            " [1.1930434 ]\n",
            " [1.1942134 ]\n",
            " [1.207277  ]\n",
            " [1.2186316 ]\n",
            " [1.2239853 ]\n",
            " [1.213467  ]\n",
            " [1.2022325 ]\n",
            " [1.2047821 ]\n",
            " [1.198772  ]\n",
            " [1.1997926 ]\n",
            " [1.2015457 ]\n",
            " [1.1884755 ]\n",
            " [1.1798631 ]\n",
            " [1.1732994 ]\n",
            " [1.1717215 ]\n",
            " [1.1771635 ]\n",
            " [1.1809251 ]\n",
            " [1.1811401 ]\n",
            " [1.1787395 ]\n",
            " [1.1833797 ]\n",
            " [1.191556  ]\n",
            " [1.1923351 ]\n",
            " [1.1951689 ]\n",
            " [1.2080001 ]\n",
            " [1.2146721 ]\n",
            " [1.2244188 ]\n",
            " [1.2326089 ]\n",
            " [1.2405452 ]\n",
            " [1.2481982 ]\n",
            " [1.2652924 ]\n",
            " [1.2725832 ]\n",
            " [1.277759  ]\n",
            " [1.2791892 ]\n",
            " [1.2862902 ]\n",
            " [1.309918  ]\n",
            " [1.2992014 ]\n",
            " [1.2739483 ]\n",
            " [1.244182  ]\n",
            " [1.2380034 ]\n",
            " [1.2302606 ]\n",
            " [1.2202283 ]\n",
            " [1.2156881 ]\n",
            " [1.2188269 ]\n",
            " [1.2156445 ]\n",
            " [1.2006193 ]\n",
            " [1.1834459 ]\n",
            " [1.1629882 ]\n",
            " [1.1629608 ]\n",
            " [1.1507896 ]\n",
            " [1.1442989 ]\n",
            " [1.1454709 ]\n",
            " [1.1545823 ]\n",
            " [1.160163  ]\n",
            " [1.1629546 ]\n",
            " [1.1706233 ]\n",
            " [1.16455   ]\n",
            " [1.1681656 ]\n",
            " [1.1628621 ]\n",
            " [1.1593158 ]\n",
            " [1.1659408 ]\n",
            " [1.1790276 ]\n",
            " [1.2039291 ]\n",
            " [1.2194244 ]\n",
            " [1.2247735 ]\n",
            " [1.2240685 ]\n",
            " [1.2294632 ]\n",
            " [1.2230605 ]\n",
            " [1.2220979 ]\n",
            " [1.2362727 ]\n",
            " [1.2492645 ]\n",
            " [1.264768  ]\n",
            " [1.2585233 ]\n",
            " [1.2568568 ]\n",
            " [1.2312647 ]\n",
            " [1.2305446 ]\n",
            " [1.2562572 ]\n",
            " [1.2670738 ]\n",
            " [1.2765535 ]\n",
            " [1.3149561 ]\n",
            " [1.3415364 ]\n",
            " [1.3504157 ]\n",
            " [1.3601117 ]\n",
            " [1.3537006 ]\n",
            " [1.3571267 ]\n",
            " [1.3591603 ]\n",
            " [1.3665067 ]\n",
            " [1.3736136 ]\n",
            " [1.374241  ]\n",
            " [1.367886  ]\n",
            " [1.3674333 ]\n",
            " [1.364443  ]\n",
            " [1.3587077 ]\n",
            " [1.363993  ]\n",
            " [1.3704057 ]\n",
            " [1.3797461 ]\n",
            " [1.3753972 ]\n",
            " [1.3836652 ]\n",
            " [1.39595   ]\n",
            " [1.4045087 ]\n",
            " [1.407746  ]\n",
            " [1.4067721 ]\n",
            " [1.4052014 ]\n",
            " [1.3964128 ]\n",
            " [1.3855704 ]\n",
            " [1.383911  ]\n",
            " [1.379696  ]\n",
            " [1.3772142 ]\n",
            " [1.3758104 ]\n",
            " [1.370613  ]\n",
            " [1.3622757 ]\n",
            " [1.3568684 ]\n",
            " [1.3526019 ]\n",
            " [1.3536612 ]\n",
            " [1.3555473 ]\n",
            " [1.3671573 ]\n",
            " [1.3701135 ]\n",
            " [1.3632241 ]\n",
            " [1.3626822 ]\n",
            " [1.3566589 ]\n",
            " [1.3556759 ]\n",
            " [1.352095  ]\n",
            " [1.3663732 ]\n",
            " [1.3812978 ]\n",
            " [1.3775475 ]\n",
            " [1.3679789 ]\n",
            " [1.365908  ]\n",
            " [1.3630341 ]\n",
            " [1.358732  ]\n",
            " [1.3719085 ]\n",
            " [1.4089296 ]\n",
            " [1.4325217 ]\n",
            " [1.4429896 ]\n",
            " [1.4483404 ]\n",
            " [1.4552209 ]\n",
            " [1.4343714 ]\n",
            " [1.4349449 ]\n",
            " [1.4263613 ]\n",
            " [1.4417986 ]\n",
            " [1.4612111 ]\n",
            " [1.5153135 ]\n",
            " [1.5346478 ]\n",
            " [1.5522919 ]\n",
            " [1.5624884 ]\n",
            " [1.5649557 ]\n",
            " [1.5690379 ]\n",
            " [1.5724311 ]\n",
            " [1.5766035 ]\n",
            " [1.5858607 ]\n",
            " [1.5896063 ]\n",
            " [1.5898447 ]\n",
            " [1.5872077 ]\n",
            " [1.5741673 ]\n",
            " [1.5650327 ]\n",
            " [1.5699183 ]\n",
            " [1.5581918 ]\n",
            " [1.5530721 ]\n",
            " [1.5628513 ]\n",
            " [1.5680892 ]\n",
            " [1.5549425 ]\n",
            " [1.5540959 ]\n",
            " [1.5698259 ]\n",
            " [1.5579168 ]\n",
            " [1.5583867 ]\n",
            " [1.5584013 ]\n",
            " [1.5748702 ]\n",
            " [1.567383  ]\n",
            " [1.5639793 ]\n",
            " [1.572887  ]\n",
            " [1.5738554 ]\n",
            " [1.5600386 ]\n",
            " [1.5542849 ]\n",
            " [1.5520561 ]\n",
            " [1.5556121 ]\n",
            " [1.555812  ]\n",
            " [1.5519856 ]\n",
            " [1.5484418 ]\n",
            " [1.5513458 ]\n",
            " [1.5554453 ]\n",
            " [1.5613976 ]\n",
            " [1.5828761 ]\n",
            " [1.6165361 ]\n",
            " [1.6345186 ]\n",
            " [1.6484493 ]\n",
            " [1.6622041 ]\n",
            " [1.6714743 ]\n",
            " [1.6682625 ]\n",
            " [1.6719581 ]\n",
            " [1.671551  ]\n",
            " [1.6821709 ]\n",
            " [1.6880895 ]\n",
            " [1.6919503 ]\n",
            " [1.6910131 ]\n",
            " [1.6891006 ]\n",
            " [1.684354  ]\n",
            " [1.6941949 ]\n",
            " [1.7034202 ]\n",
            " [1.7025757 ]\n",
            " [1.7271575 ]\n",
            " [1.7459421 ]\n",
            " [1.7483124 ]\n",
            " [1.7460809 ]\n",
            " [1.731323  ]\n",
            " [1.7302266 ]\n",
            " [1.7338507 ]\n",
            " [1.7434843 ]\n",
            " [1.7302563 ]\n",
            " [1.7124326 ]\n",
            " [1.6877457 ]\n",
            " [1.6842064 ]\n",
            " [1.6977087 ]\n",
            " [1.7034189 ]\n",
            " [1.7035209 ]\n",
            " [1.6992711 ]\n",
            " [1.7137743 ]\n",
            " [1.7191592 ]\n",
            " [1.7356714 ]\n",
            " [1.7460965 ]\n",
            " [1.7555832 ]\n",
            " [1.753147  ]\n",
            " [1.754514  ]\n",
            " [1.7590618 ]\n",
            " [1.7594768 ]\n",
            " [1.7533224 ]\n",
            " [1.7650436 ]\n",
            " [1.7740724 ]\n",
            " [1.7835069 ]\n",
            " [1.7905468 ]\n",
            " [1.7998106 ]\n",
            " [1.8027115 ]\n",
            " [1.8066357 ]\n",
            " [1.8086218 ]\n",
            " [1.8061606 ]\n",
            " [1.8100729 ]\n",
            " [1.806933  ]\n",
            " [1.810577  ]\n",
            " [1.815401  ]\n",
            " [1.8157779 ]\n",
            " [1.8200982 ]\n",
            " [1.8198649 ]\n",
            " [1.8186135 ]\n",
            " [1.8144436 ]\n",
            " [1.80854   ]\n",
            " [1.8108922 ]\n",
            " [1.8248501 ]\n",
            " [1.8364561 ]\n",
            " [1.8438977 ]\n",
            " [1.8400204 ]\n",
            " [1.8420995 ]\n",
            " [1.848576  ]\n",
            " [1.8547258 ]\n",
            " [1.8633331 ]\n",
            " [1.8615673 ]\n",
            " [1.8632287 ]\n",
            " [1.8510524 ]\n",
            " [1.855281  ]\n",
            " [1.8642133 ]\n",
            " [1.8729287 ]\n",
            " [1.8988748 ]\n",
            " [1.9178017 ]\n",
            " [1.9117826 ]\n",
            " [1.9106655 ]\n",
            " [1.9092696 ]\n",
            " [1.9019126 ]\n",
            " [1.9028381 ]\n",
            " [1.9037695 ]\n",
            " [1.9047726 ]\n",
            " [1.9088799 ]\n",
            " [1.9110725 ]\n",
            " [1.9167368 ]\n",
            " [1.9202148 ]\n",
            " [1.9204938 ]\n",
            " [1.9221131 ]\n",
            " [1.9246442 ]\n",
            " [1.9252187 ]\n",
            " [1.9202803 ]\n",
            " [1.9156848 ]\n",
            " [1.9131458 ]\n",
            " [1.9201705 ]\n",
            " [1.9368272 ]\n",
            " [1.9501868 ]\n",
            " [1.9582403 ]\n",
            " [1.957826  ]\n",
            " [1.9676038 ]\n",
            " [1.9782246 ]\n",
            " [1.9822644 ]\n",
            " [1.986405  ]\n",
            " [1.9806353 ]\n",
            " [1.979602  ]\n",
            " [1.9836956 ]\n",
            " [1.9824191 ]\n",
            " [1.9825602 ]\n",
            " [1.969759  ]\n",
            " [1.9703885 ]\n",
            " [1.971593  ]\n",
            " [1.9774867 ]\n",
            " [1.9774361 ]\n",
            " [1.9641141 ]\n",
            " [1.9427053 ]\n",
            " [1.942504  ]\n",
            " [1.9474875 ]\n",
            " [1.9539353 ]\n",
            " [1.958181  ]\n",
            " [1.954864  ]\n",
            " [1.9272431 ]\n",
            " [1.9100014 ]\n",
            " [1.8965734 ]\n",
            " [1.9042405 ]\n",
            " [1.8925879 ]\n",
            " [1.9013578 ]\n",
            " [1.9086553 ]\n",
            " [1.9247053 ]\n",
            " [1.9339906 ]\n",
            " [1.9322451 ]\n",
            " [1.9210291 ]\n",
            " [1.9218835 ]\n",
            " [1.9398913 ]\n",
            " [1.9486213 ]\n",
            " [1.9562106 ]\n",
            " [1.9652481 ]\n",
            " [1.962538  ]\n",
            " [1.9617369 ]\n",
            " [1.9407821 ]\n",
            " [1.9331602 ]\n",
            " [1.938412  ]\n",
            " [1.968314  ]\n",
            " [1.981008  ]\n",
            " [1.993589  ]\n",
            " [1.9813446 ]\n",
            " [1.985683  ]\n",
            " [1.9912223 ]\n",
            " [2.0031617 ]\n",
            " [2.0115705 ]\n",
            " [2.0157704 ]\n",
            " [2.0148149 ]\n",
            " [2.0022397 ]\n",
            " [2.00109   ]\n",
            " [2.0111938 ]\n",
            " [2.0159502 ]\n",
            " [2.0156453 ]\n",
            " [2.0160022 ]\n",
            " [2.023428  ]\n",
            " [2.0244036 ]\n",
            " [2.0113206 ]\n",
            " [2.0018969 ]\n",
            " [1.998942  ]\n",
            " [1.9801284 ]\n",
            " [1.9889215 ]\n",
            " [1.975594  ]\n",
            " [1.9677411 ]\n",
            " [1.970052  ]\n",
            " [1.9671314 ]\n",
            " [1.969101  ]\n",
            " [1.9926181 ]\n",
            " [2.0039701 ]\n",
            " [2.0059533 ]\n",
            " [2.009059  ]\n",
            " [2.0019531 ]\n",
            " [1.9868823 ]\n",
            " [1.9925615 ]\n",
            " [1.9883754 ]\n",
            " [1.9735898 ]\n",
            " [1.9646138 ]\n",
            " [1.9719093 ]\n",
            " [1.9868562 ]\n",
            " [1.996169  ]\n",
            " [2.0025764 ]\n",
            " [1.9979957 ]\n",
            " [1.9957136 ]\n",
            " [1.9939233 ]\n",
            " [1.9871897 ]\n",
            " [1.9844706 ]\n",
            " [1.9825927 ]\n",
            " [1.9493107 ]\n",
            " [1.9337025 ]\n",
            " [1.9250143 ]\n",
            " [1.9229949 ]\n",
            " [1.9326129 ]\n",
            " [1.9484061 ]\n",
            " [1.9416208 ]\n",
            " [1.9376725 ]\n",
            " [1.9193994 ]\n",
            " [1.9130644 ]\n",
            " [1.8997444 ]\n",
            " [1.8756579 ]\n",
            " [1.8568207 ]\n",
            " [1.8390878 ]\n",
            " [1.8466766 ]\n",
            " [1.8491842 ]\n",
            " [1.86384   ]\n",
            " [1.8836973 ]\n",
            " [1.9029934 ]\n",
            " [1.9697461 ]\n",
            " [1.9626383 ]\n",
            " [1.9576389 ]\n",
            " [1.942821  ]\n",
            " [1.9345351 ]\n",
            " [1.9464331 ]\n",
            " [1.936095  ]\n",
            " [1.9100317 ]\n",
            " [1.9029888 ]\n",
            " [1.9098852 ]\n",
            " [1.9136752 ]\n",
            " [1.8917443 ]\n",
            " [1.8736597 ]\n",
            " [1.8585517 ]\n",
            " [1.8466692 ]\n",
            " [1.8554654 ]\n",
            " [1.8764697 ]\n",
            " [1.8854511 ]\n",
            " [1.8870531 ]\n",
            " [1.8899709 ]\n",
            " [1.8907634 ]\n",
            " [1.8769647 ]\n",
            " [1.8454906 ]\n",
            " [1.8359572 ]\n",
            " [1.8652014 ]\n",
            " [1.869635  ]\n",
            " [1.8632149 ]\n",
            " [1.8398407 ]\n",
            " [1.8423669 ]\n",
            " [1.8637716 ]\n",
            " [1.8785322 ]\n",
            " [1.89285   ]\n",
            " [1.8997    ]\n",
            " [1.9205658 ]\n",
            " [1.92258   ]\n",
            " [1.9349387 ]\n",
            " [1.9427437 ]\n",
            " [1.947115  ]\n",
            " [1.9588484 ]\n",
            " [1.959817  ]\n",
            " [1.9467686 ]\n",
            " [1.9445847 ]\n",
            " [1.9587218 ]\n",
            " [1.9541829 ]\n",
            " [1.9307206 ]\n",
            " [1.9178869 ]\n",
            " [1.9029893 ]\n",
            " [1.8745948 ]\n",
            " [1.8574208 ]\n",
            " [1.8565493 ]\n",
            " [1.8431754 ]\n",
            " [1.8376489 ]\n",
            " [1.8472885 ]\n",
            " [1.8433734 ]\n",
            " [1.8237692 ]\n",
            " [1.7853805 ]\n",
            " [1.7822765 ]\n",
            " [1.7676325 ]\n",
            " [1.7294074 ]\n",
            " [1.7387823 ]\n",
            " [1.7218688 ]\n",
            " [1.7189319 ]\n",
            " [1.7277914 ]\n",
            " [1.7486833 ]\n",
            " [1.7308643 ]\n",
            " [1.7154276 ]\n",
            " [1.6962713 ]\n",
            " [1.698638  ]\n",
            " [1.695365  ]\n",
            " [1.683263  ]\n",
            " [1.7005392 ]\n",
            " [1.698903  ]\n",
            " [1.7082219 ]\n",
            " [1.688475  ]\n",
            " [1.6701864 ]\n",
            " [1.6520184 ]\n",
            " [1.6564621 ]\n",
            " [1.6188794 ]\n",
            " [1.6071972 ]\n",
            " [1.6164898 ]]\n",
            "\n",
            "Prediction Shape- (835, 1)\n"
          ]
        }
      ],
      "source": [
        "print(\"prediction\\n\", prediction)\n",
        "print(\"\\nPrediction Shape-\",prediction.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "fvxk4sbQ9r6a",
        "outputId": "c1e86004-e219-4c23-a5cd-a555a6323e2e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-a434fa8b0e5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: non-broadcastable output operand with shape (835,1) doesn't match the broadcast shape (835,5)"
          ]
        }
      ],
      "source": [
        "scaler.inverse_transform(prediction)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gV3_bAM9r6a"
      },
      "outputs": [],
      "source": [
        "prediction_copies_array = np.repeat(prediction,5, axis=-1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPVJuQoV9r6b"
      },
      "outputs": [],
      "source": [
        "pred=scaler.inverse_transform(np.reshape(prediction_copies_array,(len(prediction),5)))[:,0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7o5l3rgV9r6b",
        "outputId": "d36aa266-48fc-4a20-b846-9a6f8543ba9d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1140.9346, 1140.1388, 1129.7642, 1122.2118, 1119.9803, 1127.6133,\n",
              "       1134.2568, 1136.724 , 1136.6431, 1136.4651, 1135.4894, 1129.1055,\n",
              "       1128.2068, 1129.9194, 1131.2999, 1132.1262, 1134.9373, 1143.9633,\n",
              "       1152.9133, 1162.9852, 1168.8989, 1166.1619, 1161.6012, 1171.0582,\n",
              "       1186.6567, 1197.4437, 1200.2499, 1201.188 , 1200.8467, 1205.7637,\n",
              "       1217.3728, 1228.0522, 1227.0586, 1219.6504, 1212.941 , 1204.2185,\n",
              "       1197.1019, 1195.4286, 1202.5687, 1209.0237, 1215.9392, 1222.0372,\n",
              "       1223.8848, 1222.9403, 1219.6011, 1219.5835, 1221.0991, 1226.5142,\n",
              "       1230.9741, 1236.2133, 1242.8132, 1247.3733, 1252.4479, 1262.1245,\n",
              "       1266.786 , 1270.7096, 1276.2744, 1284.7241, 1249.4994, 1223.7915,\n",
              "       1207.7788, 1206.6873, 1206.8914, 1202.7755, 1197.7368, 1191.6466,\n",
              "       1188.0496, 1174.6464, 1163.1648, 1167.6752, 1180.5643, 1183.2125,\n",
              "       1173.2686, 1170.7931, 1171.4675, 1167.0327, 1163.0905, 1160.9161,\n",
              "       1152.1327, 1146.6488, 1138.4089, 1108.2461, 1092.8041, 1082.9211,\n",
              "       1077.2927, 1081.3936, 1091.0841, 1097.7158, 1097.9211, 1102.1385,\n",
              "       1104.1836, 1107.5564, 1114.9541, 1117.9199, 1123.4725, 1129.4104,\n",
              "       1131.8461, 1123.5104, 1113.8381, 1107.7589, 1105.128 , 1111.5327,\n",
              "       1119.3226, 1128.4248, 1136.313 , 1136.5583, 1137.57  , 1145.5256,\n",
              "       1153.138 , 1157.0924, 1160.7747, 1164.6058, 1165.493 , 1163.9595,\n",
              "       1159.5641, 1157.426 , 1159.8142, 1158.4413, 1155.6722, 1200.3624,\n",
              "       1224.4214, 1230.3242, 1230.0737, 1228.2079, 1220.8936, 1200.3937,\n",
              "       1194.7917, 1192.6656, 1202.8081, 1206.1774, 1201.2407, 1204.5823,\n",
              "       1197.2987, 1192.7733, 1194.946 , 1204.4866, 1205.0115, 1207.201 ,\n",
              "       1207.4896, 1195.2717, 1190.4247, 1190.5825, 1190.1569, 1198.5775,\n",
              "       1203.4442, 1197.8406, 1197.862 , 1209.3154, 1215.934 , 1218.3473,\n",
              "       1219.2098, 1224.7872, 1235.0632, 1242.586 , 1244.2723, 1244.3256,\n",
              "       1244.6694, 1248.52  , 1248.0542, 1248.2125, 1244.6777, 1248.2732,\n",
              "       1252.101 , 1248.8213, 1243.408 , 1236.9235, 1221.4327, 1213.4462,\n",
              "       1218.4497, 1223.3062, 1218.9655, 1220.069 , 1222.7971, 1228.7322,\n",
              "       1231.7256, 1241.2927, 1249.567 , 1257.979 , 1259.8761, 1260.6101,\n",
              "       1260.2296, 1264.4677, 1269.3511, 1272.5635, 1284.6102, 1282.5862,\n",
              "       1278.7253, 1277.0175, 1281.0161, 1290.4203, 1297.8085, 1300.3622,\n",
              "       1308.5079, 1314.7479, 1313.8143, 1313.2386, 1312.3958, 1316.303 ,\n",
              "       1327.5226, 1330.9009, 1330.1859, 1323.8632, 1319.9215, 1316.6792,\n",
              "       1318.2787, 1322.0967, 1324.667 , 1322.7568, 1315.572 , 1311.605 ,\n",
              "       1320.5901, 1329.364 , 1339.0271, 1346.1312, 1349.452 , 1352.3607,\n",
              "       1355.2925, 1356.6025, 1362.3871, 1364.2869, 1364.114 , 1364.5779,\n",
              "       1364.2023, 1363.2245, 1360.4397, 1363.7854, 1364.833 , 1358.9788,\n",
              "       1354.1152, 1362.278 , 1365.7976, 1376.9108, 1388.1962, 1396.9504,\n",
              "       1408.782 , 1418.8165, 1427.5797, 1430.6316, 1434.339 , 1441.8707,\n",
              "       1456.6072, 1467.323 , 1475.3495, 1479.1033, 1475.17  , 1456.2549,\n",
              "       1454.3418, 1458.0643, 1456.8765, 1451.8169, 1465.4935, 1458.6488,\n",
              "       1455.2548, 1463.2245, 1470.3483, 1483.0408, 1494.4825, 1502.2758,\n",
              "       1505.2535, 1508.4989, 1511.2468, 1515.7977, 1514.5612, 1502.1162,\n",
              "       1467.5883, 1440.7035, 1426.2545, 1391.5929, 1369.1038, 1379.8365,\n",
              "       1376.9565, 1382.9924, 1364.3138, 1339.4226, 1296.1964, 1293.2484,\n",
              "       1273.8898, 1222.9165, 1221.6688, 1181.2805, 1161.1313, 1141.4541,\n",
              "       1139.4089, 1129.998 , 1108.808 , 1124.6368, 1129.66  , 1145.1064,\n",
              "       1142.7292, 1147.7015, 1160.334 , 1147.7332, 1141.5817, 1133.074 ,\n",
              "       1157.2114, 1181.3539, 1199.0807, 1210.4218, 1216.4921, 1241.0615,\n",
              "       1254.0801, 1261.9392, 1275.0664, 1276.8861, 1259.0977, 1265.0907,\n",
              "       1276.6023, 1280.7966, 1285.7495, 1274.8438, 1308.5085, 1328.5298,\n",
              "       1329.9315, 1329.1078, 1342.2618, 1350.666 , 1362.1515, 1375.7975,\n",
              "       1387.5115, 1387.7146, 1374.8379, 1366.7327, 1370.3967, 1378.0046,\n",
              "       1381.8947, 1394.2129, 1401.2012, 1405.6863, 1414.6382, 1415.9795,\n",
              "       1416.9219, 1422.7123, 1427.445 , 1432.2766, 1435.7789, 1428.8997,\n",
              "       1431.6075, 1437.3506, 1446.404 , 1455.3796, 1438.0961, 1428.6976,\n",
              "       1424.5243, 1435.2833, 1443.6368, 1442.7802, 1440.415 , 1444.2489,\n",
              "       1453.5624, 1449.0454, 1445.0503, 1417.1315, 1406.133 , 1411.709 ,\n",
              "       1424.8307, 1444.0513, 1465.6072, 1475.1892, 1482.3213, 1491.5293,\n",
              "       1505.6841, 1509.4532, 1506.6805, 1507.4409, 1506.8198, 1508.2491,\n",
              "       1524.2076, 1538.0782, 1544.6183, 1531.7692, 1518.0452, 1521.1598,\n",
              "       1513.8179, 1515.0647, 1517.2063, 1501.2399, 1490.719 , 1482.7009,\n",
              "       1480.7732, 1487.4211, 1492.0164, 1492.2789, 1489.3464, 1495.0148,\n",
              "       1505.0029, 1505.9547, 1509.4164, 1525.0908, 1533.2413, 1545.1477,\n",
              "       1555.1527, 1564.8477, 1574.1964, 1595.0786, 1603.985 , 1610.3076,\n",
              "       1612.0548, 1620.7292, 1649.5929, 1636.5015, 1605.6526, 1569.2903,\n",
              "       1561.7426, 1552.284 , 1540.0288, 1534.4824, 1538.3168, 1534.4292,\n",
              "       1516.0746, 1495.0957, 1470.1047, 1470.0713, 1455.2031, 1447.2742,\n",
              "       1448.7058, 1459.8362, 1466.6536, 1470.0637, 1479.4318, 1472.0126,\n",
              "       1476.4294, 1469.9507, 1465.6187, 1473.7115, 1489.6984, 1520.1178,\n",
              "       1539.0466, 1545.5812, 1544.72  , 1551.31  , 1543.4885, 1542.3126,\n",
              "       1559.6284, 1575.499 , 1594.438 , 1586.8096, 1584.7738, 1553.5107,\n",
              "       1552.631 , 1584.0413, 1597.2546, 1608.8351, 1655.7472, 1688.2175,\n",
              "       1699.0645, 1710.9089, 1703.0773, 1707.2625, 1709.7467, 1718.721 ,\n",
              "       1727.4027, 1728.1692, 1720.4059, 1719.8529, 1716.2   , 1709.1937,\n",
              "       1715.6504, 1723.4839, 1734.894 , 1729.5815, 1739.6816, 1754.6886,\n",
              "       1765.1439, 1769.0985, 1767.9088, 1765.9901, 1755.254 , 1742.009 ,\n",
              "       1739.9819, 1734.8329, 1731.8011, 1730.0863, 1723.7372, 1713.5525,\n",
              "       1706.9469, 1701.735 , 1703.029 , 1705.3331, 1719.5157, 1723.127 ,\n",
              "       1714.711 , 1714.0491, 1706.691 , 1705.4902, 1701.1158, 1718.5579,\n",
              "       1736.7897, 1732.2084, 1720.5194, 1717.9896, 1714.4789, 1709.2235,\n",
              "       1725.3198, 1770.5444, 1799.3643, 1812.1517, 1818.6882, 1827.0934,\n",
              "       1801.6238, 1802.3243, 1791.8389, 1810.6968, 1834.4109, 1900.502 ,\n",
              "       1924.1205, 1945.6743, 1958.1304, 1961.1444, 1966.1311, 1970.2762,\n",
              "       1975.3732, 1986.6818, 1991.2572, 1991.5485, 1988.3271, 1972.3971,\n",
              "       1961.2384, 1967.2065, 1952.8816, 1946.6274, 1958.5736, 1964.9723,\n",
              "       1948.9124, 1947.878 , 1967.0938, 1952.5457, 1953.1198, 1953.1376,\n",
              "       1973.2559, 1964.1096, 1959.9515, 1970.8331, 1972.0161, 1955.1376,\n",
              "       1948.109 , 1945.3862, 1949.7302, 1949.9745, 1945.3002, 1940.9711,\n",
              "       1944.5187, 1949.5266, 1956.7977, 1983.0358, 2024.1545, 2046.1217,\n",
              "       2063.1394, 2079.9421, 2091.2664, 2087.343 , 2091.8574, 2091.36  ,\n",
              "       2104.3333, 2111.5635, 2116.2798, 2115.1348, 2112.7986, 2107.    ,\n",
              "       2119.0217, 2130.2913, 2129.2595, 2159.2883, 2182.2356, 2185.131 ,\n",
              "       2182.405 , 2164.377 , 2163.0376, 2167.4648, 2179.2332, 2163.074 ,\n",
              "       2141.3008, 2111.1433, 2106.8198, 2123.3142, 2130.2896, 2130.4143,\n",
              "       2125.2227, 2142.9397, 2149.5178, 2169.689 , 2182.424 , 2194.013 ,\n",
              "       2191.037 , 2192.7068, 2198.2625, 2198.7693, 2191.2512, 2205.5698,\n",
              "       2216.5994, 2228.1243, 2236.724 , 2248.0408, 2251.5845, 2256.3784,\n",
              "       2258.8044, 2255.7979, 2260.5771, 2256.7415, 2261.1929, 2267.086 ,\n",
              "       2267.5464, 2272.824 , 2272.5388, 2271.0103, 2265.9163, 2258.7046,\n",
              "       2261.578 , 2278.6287, 2292.8066, 2301.8972, 2297.1606, 2299.7004,\n",
              "       2307.612 , 2315.1248, 2325.6392, 2323.4822, 2325.5117, 2310.6372,\n",
              "       2315.803 , 2326.7146, 2337.361 , 2369.0566, 2392.1775, 2384.8247,\n",
              "       2383.46  , 2381.755 , 2372.7676, 2373.8982, 2375.036 , 2376.2615,\n",
              "       2381.2788, 2383.9573, 2390.8767, 2395.1252, 2395.4663, 2397.4443,\n",
              "       2400.5364, 2401.238 , 2395.2053, 2389.5916, 2386.49  , 2395.0713,\n",
              "       2415.419 , 2431.739 , 2441.577 , 2441.0708, 2453.0154, 2465.9897,\n",
              "       2470.9246, 2475.9827, 2468.9346, 2467.672 , 2472.6729, 2471.1135,\n",
              "       2471.286 , 2455.6482, 2456.4172, 2457.8884, 2465.0881, 2465.0264,\n",
              "       2448.7522, 2422.5996, 2422.3538, 2428.4414, 2436.3179, 2441.5046,\n",
              "       2437.4526, 2403.7112, 2382.6487, 2366.2454, 2375.6113, 2361.3767,\n",
              "       2372.0898, 2381.0044, 2400.6108, 2411.9539, 2409.8215, 2396.12  ,\n",
              "       2397.1638, 2419.162 , 2429.8264, 2439.0974, 2450.1377, 2446.8271,\n",
              "       2445.8486, 2420.2502, 2410.9395, 2417.3547, 2453.883 , 2469.39  ,\n",
              "       2484.7585, 2469.801 , 2475.1008, 2481.8674, 2496.4526, 2506.7246,\n",
              "       2511.8555, 2510.688 , 2495.3264, 2493.9219, 2506.2644, 2512.075 ,\n",
              "       2511.7024, 2512.1384, 2521.2097, 2522.4016, 2506.4194, 2494.9075,\n",
              "       2491.2979, 2468.3152, 2479.057 , 2462.7764, 2453.183 , 2456.006 ,\n",
              "       2452.4385, 2454.8445, 2483.5728, 2497.4402, 2499.8628, 2503.6567,\n",
              "       2494.9763, 2476.5657, 2483.5034, 2478.39  , 2460.3276, 2449.3628,\n",
              "       2458.275 , 2476.534 , 2487.9102, 2495.7375, 2490.1418, 2487.354 ,\n",
              "       2485.167 , 2476.9412, 2473.6199, 2471.3257, 2430.6687, 2411.6018,\n",
              "       2400.9883, 2398.5215, 2410.2708, 2429.5635, 2421.2747, 2416.4514,\n",
              "       2394.1292, 2386.3904, 2370.119 , 2340.695 , 2317.6838, 2296.0215,\n",
              "       2305.2917, 2308.355 , 2326.2585, 2350.5159, 2374.088 , 2455.6326,\n",
              "       2446.9495, 2440.8423, 2422.741 , 2412.619 , 2427.1533, 2414.5244,\n",
              "       2382.6858, 2374.0823, 2382.5068, 2387.1367, 2360.346 , 2338.2542,\n",
              "       2319.7983, 2305.2827, 2316.028 , 2341.6868, 2352.6584, 2354.6155,\n",
              "       2358.1797, 2359.148 , 2342.2915, 2303.843 , 2292.197 , 2327.9214,\n",
              "       2333.3376, 2325.4949, 2296.9412, 2300.027 , 2326.1748, 2344.2063,\n",
              "       2361.6968, 2370.0647, 2395.5542, 2398.0146, 2413.1118, 2422.6465,\n",
              "       2427.9863, 2442.3198, 2443.5032, 2427.5632, 2424.8955, 2442.165 ,\n",
              "       2436.6204, 2407.9592, 2392.2815, 2374.0828, 2339.3965, 2318.4167,\n",
              "       2317.3523, 2301.015 , 2294.2637, 2306.0393, 2301.2566, 2277.3083,\n",
              "       2230.413 , 2226.6213, 2208.7324, 2162.0369, 2173.4893, 2152.828 ,\n",
              "       2149.2402, 2160.063 , 2185.5842, 2163.8167, 2144.9595, 2121.558 ,\n",
              "       2124.4492, 2120.451 , 2105.6672, 2126.772 , 2124.773 , 2136.157 ,\n",
              "       2112.0344, 2089.693 , 2067.4993, 2072.9277, 2027.0171, 2012.7461,\n",
              "       2024.0979], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjU8_GH69r6c"
      },
      "outputs": [],
      "source": [
        "original_copies_array = np.repeat(testY,5, axis=-1)\n",
        "\n",
        "original_copies_array.shape\n",
        "\n",
        "original=scaler.inverse_transform(np.reshape(original_copies_array,(len(testY),5)))[:,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdyHNXfS9r6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "075f59f2-8170-4a60-d23d-6767431b6c51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred Values--  [1140.9346 1140.1388 1129.7642 1122.2118 1119.9803 1127.6133 1134.2568\n",
            " 1136.724  1136.6431 1136.4651 1135.4894 1129.1055 1128.2068 1129.9194\n",
            " 1131.2999 1132.1262 1134.9373 1143.9633 1152.9133 1162.9852 1168.8989\n",
            " 1166.1619 1161.6012 1171.0582 1186.6567 1197.4437 1200.2499 1201.188\n",
            " 1200.8467 1205.7637 1217.3728 1228.0522 1227.0586 1219.6504 1212.941\n",
            " 1204.2185 1197.1019 1195.4286 1202.5687 1209.0237 1215.9392 1222.0372\n",
            " 1223.8848 1222.9403 1219.6011 1219.5835 1221.0991 1226.5142 1230.9741\n",
            " 1236.2133 1242.8132 1247.3733 1252.4479 1262.1245 1266.786  1270.7096\n",
            " 1276.2744 1284.7241 1249.4994 1223.7915 1207.7788 1206.6873 1206.8914\n",
            " 1202.7755 1197.7368 1191.6466 1188.0496 1174.6464 1163.1648 1167.6752\n",
            " 1180.5643 1183.2125 1173.2686 1170.7931 1171.4675 1167.0327 1163.0905\n",
            " 1160.9161 1152.1327 1146.6488 1138.4089 1108.2461 1092.8041 1082.9211\n",
            " 1077.2927 1081.3936 1091.0841 1097.7158 1097.9211 1102.1385 1104.1836\n",
            " 1107.5564 1114.9541 1117.9199 1123.4725 1129.4104 1131.8461 1123.5104\n",
            " 1113.8381 1107.7589 1105.128  1111.5327 1119.3226 1128.4248 1136.313\n",
            " 1136.5583 1137.57   1145.5256 1153.138  1157.0924 1160.7747 1164.6058\n",
            " 1165.493  1163.9595 1159.5641 1157.426  1159.8142 1158.4413 1155.6722\n",
            " 1200.3624 1224.4214 1230.3242 1230.0737 1228.2079 1220.8936 1200.3937\n",
            " 1194.7917 1192.6656 1202.8081 1206.1774 1201.2407 1204.5823 1197.2987\n",
            " 1192.7733 1194.946  1204.4866 1205.0115 1207.201  1207.4896 1195.2717\n",
            " 1190.4247 1190.5825 1190.1569 1198.5775 1203.4442 1197.8406 1197.862\n",
            " 1209.3154 1215.934  1218.3473 1219.2098 1224.7872 1235.0632 1242.586\n",
            " 1244.2723 1244.3256 1244.6694 1248.52   1248.0542 1248.2125 1244.6777\n",
            " 1248.2732 1252.101  1248.8213 1243.408  1236.9235 1221.4327 1213.4462\n",
            " 1218.4497 1223.3062 1218.9655 1220.069  1222.7971 1228.7322 1231.7256\n",
            " 1241.2927 1249.567  1257.979  1259.8761 1260.6101 1260.2296 1264.4677\n",
            " 1269.3511 1272.5635 1284.6102 1282.5862 1278.7253 1277.0175 1281.0161\n",
            " 1290.4203 1297.8085 1300.3622 1308.5079 1314.7479 1313.8143 1313.2386\n",
            " 1312.3958 1316.303  1327.5226 1330.9009 1330.1859 1323.8632 1319.9215\n",
            " 1316.6792 1318.2787 1322.0967 1324.667  1322.7568 1315.572  1311.605\n",
            " 1320.5901 1329.364  1339.0271 1346.1312 1349.452  1352.3607 1355.2925\n",
            " 1356.6025 1362.3871 1364.2869 1364.114  1364.5779 1364.2023 1363.2245\n",
            " 1360.4397 1363.7854 1364.833  1358.9788 1354.1152 1362.278  1365.7976\n",
            " 1376.9108 1388.1962 1396.9504 1408.782  1418.8165 1427.5797 1430.6316\n",
            " 1434.339  1441.8707 1456.6072 1467.323  1475.3495 1479.1033 1475.17\n",
            " 1456.2549 1454.3418 1458.0643 1456.8765 1451.8169 1465.4935 1458.6488\n",
            " 1455.2548 1463.2245 1470.3483 1483.0408 1494.4825 1502.2758 1505.2535\n",
            " 1508.4989 1511.2468 1515.7977 1514.5612 1502.1162 1467.5883 1440.7035\n",
            " 1426.2545 1391.5929 1369.1038 1379.8365 1376.9565 1382.9924 1364.3138\n",
            " 1339.4226 1296.1964 1293.2484 1273.8898 1222.9165 1221.6688 1181.2805\n",
            " 1161.1313 1141.4541 1139.4089 1129.998  1108.808  1124.6368 1129.66\n",
            " 1145.1064 1142.7292 1147.7015 1160.334  1147.7332 1141.5817 1133.074\n",
            " 1157.2114 1181.3539 1199.0807 1210.4218 1216.4921 1241.0615 1254.0801\n",
            " 1261.9392 1275.0664 1276.8861 1259.0977 1265.0907 1276.6023 1280.7966\n",
            " 1285.7495 1274.8438 1308.5085 1328.5298 1329.9315 1329.1078 1342.2618\n",
            " 1350.666  1362.1515 1375.7975 1387.5115 1387.7146 1374.8379 1366.7327\n",
            " 1370.3967 1378.0046 1381.8947 1394.2129 1401.2012 1405.6863 1414.6382\n",
            " 1415.9795 1416.9219 1422.7123 1427.445  1432.2766 1435.7789 1428.8997\n",
            " 1431.6075 1437.3506 1446.404  1455.3796 1438.0961 1428.6976 1424.5243\n",
            " 1435.2833 1443.6368 1442.7802 1440.415  1444.2489 1453.5624 1449.0454\n",
            " 1445.0503 1417.1315 1406.133  1411.709  1424.8307 1444.0513 1465.6072\n",
            " 1475.1892 1482.3213 1491.5293 1505.6841 1509.4532 1506.6805 1507.4409\n",
            " 1506.8198 1508.2491 1524.2076 1538.0782 1544.6183 1531.7692 1518.0452\n",
            " 1521.1598 1513.8179 1515.0647 1517.2063 1501.2399 1490.719  1482.7009\n",
            " 1480.7732 1487.4211 1492.0164 1492.2789 1489.3464 1495.0148 1505.0029\n",
            " 1505.9547 1509.4164 1525.0908 1533.2413 1545.1477 1555.1527 1564.8477\n",
            " 1574.1964 1595.0786 1603.985  1610.3076 1612.0548 1620.7292 1649.5929\n",
            " 1636.5015 1605.6526 1569.2903 1561.7426 1552.284  1540.0288 1534.4824\n",
            " 1538.3168 1534.4292 1516.0746 1495.0957 1470.1047 1470.0713 1455.2031\n",
            " 1447.2742 1448.7058 1459.8362 1466.6536 1470.0637 1479.4318 1472.0126\n",
            " 1476.4294 1469.9507 1465.6187 1473.7115 1489.6984 1520.1178 1539.0466\n",
            " 1545.5812 1544.72   1551.31   1543.4885 1542.3126 1559.6284 1575.499\n",
            " 1594.438  1586.8096 1584.7738 1553.5107 1552.631  1584.0413 1597.2546\n",
            " 1608.8351 1655.7472 1688.2175 1699.0645 1710.9089 1703.0773 1707.2625\n",
            " 1709.7467 1718.721  1727.4027 1728.1692 1720.4059 1719.8529 1716.2\n",
            " 1709.1937 1715.6504 1723.4839 1734.894  1729.5815 1739.6816 1754.6886\n",
            " 1765.1439 1769.0985 1767.9088 1765.9901 1755.254  1742.009  1739.9819\n",
            " 1734.8329 1731.8011 1730.0863 1723.7372 1713.5525 1706.9469 1701.735\n",
            " 1703.029  1705.3331 1719.5157 1723.127  1714.711  1714.0491 1706.691\n",
            " 1705.4902 1701.1158 1718.5579 1736.7897 1732.2084 1720.5194 1717.9896\n",
            " 1714.4789 1709.2235 1725.3198 1770.5444 1799.3643 1812.1517 1818.6882\n",
            " 1827.0934 1801.6238 1802.3243 1791.8389 1810.6968 1834.4109 1900.502\n",
            " 1924.1205 1945.6743 1958.1304 1961.1444 1966.1311 1970.2762 1975.3732\n",
            " 1986.6818 1991.2572 1991.5485 1988.3271 1972.3971 1961.2384 1967.2065\n",
            " 1952.8816 1946.6274 1958.5736 1964.9723 1948.9124 1947.878  1967.0938\n",
            " 1952.5457 1953.1198 1953.1376 1973.2559 1964.1096 1959.9515 1970.8331\n",
            " 1972.0161 1955.1376 1948.109  1945.3862 1949.7302 1949.9745 1945.3002\n",
            " 1940.9711 1944.5187 1949.5266 1956.7977 1983.0358 2024.1545 2046.1217\n",
            " 2063.1394 2079.9421 2091.2664 2087.343  2091.8574 2091.36   2104.3333\n",
            " 2111.5635 2116.2798 2115.1348 2112.7986 2107.     2119.0217 2130.2913\n",
            " 2129.2595 2159.2883 2182.2356 2185.131  2182.405  2164.377  2163.0376\n",
            " 2167.4648 2179.2332 2163.074  2141.3008 2111.1433 2106.8198 2123.3142\n",
            " 2130.2896 2130.4143 2125.2227 2142.9397 2149.5178 2169.689  2182.424\n",
            " 2194.013  2191.037  2192.7068 2198.2625 2198.7693 2191.2512 2205.5698\n",
            " 2216.5994 2228.1243 2236.724  2248.0408 2251.5845 2256.3784 2258.8044\n",
            " 2255.7979 2260.5771 2256.7415 2261.1929 2267.086  2267.5464 2272.824\n",
            " 2272.5388 2271.0103 2265.9163 2258.7046 2261.578  2278.6287 2292.8066\n",
            " 2301.8972 2297.1606 2299.7004 2307.612  2315.1248 2325.6392 2323.4822\n",
            " 2325.5117 2310.6372 2315.803  2326.7146 2337.361  2369.0566 2392.1775\n",
            " 2384.8247 2383.46   2381.755  2372.7676 2373.8982 2375.036  2376.2615\n",
            " 2381.2788 2383.9573 2390.8767 2395.1252 2395.4663 2397.4443 2400.5364\n",
            " 2401.238  2395.2053 2389.5916 2386.49   2395.0713 2415.419  2431.739\n",
            " 2441.577  2441.0708 2453.0154 2465.9897 2470.9246 2475.9827 2468.9346\n",
            " 2467.672  2472.6729 2471.1135 2471.286  2455.6482 2456.4172 2457.8884\n",
            " 2465.0881 2465.0264 2448.7522 2422.5996 2422.3538 2428.4414 2436.3179\n",
            " 2441.5046 2437.4526 2403.7112 2382.6487 2366.2454 2375.6113 2361.3767\n",
            " 2372.0898 2381.0044 2400.6108 2411.9539 2409.8215 2396.12   2397.1638\n",
            " 2419.162  2429.8264 2439.0974 2450.1377 2446.8271 2445.8486 2420.2502\n",
            " 2410.9395 2417.3547 2453.883  2469.39   2484.7585 2469.801  2475.1008\n",
            " 2481.8674 2496.4526 2506.7246 2511.8555 2510.688  2495.3264 2493.9219\n",
            " 2506.2644 2512.075  2511.7024 2512.1384 2521.2097 2522.4016 2506.4194\n",
            " 2494.9075 2491.2979 2468.3152 2479.057  2462.7764 2453.183  2456.006\n",
            " 2452.4385 2454.8445 2483.5728 2497.4402 2499.8628 2503.6567 2494.9763\n",
            " 2476.5657 2483.5034 2478.39   2460.3276 2449.3628 2458.275  2476.534\n",
            " 2487.9102 2495.7375 2490.1418 2487.354  2485.167  2476.9412 2473.6199\n",
            " 2471.3257 2430.6687 2411.6018 2400.9883 2398.5215 2410.2708 2429.5635\n",
            " 2421.2747 2416.4514 2394.1292 2386.3904 2370.119  2340.695  2317.6838\n",
            " 2296.0215 2305.2917 2308.355  2326.2585 2350.5159 2374.088  2455.6326\n",
            " 2446.9495 2440.8423 2422.741  2412.619  2427.1533 2414.5244 2382.6858\n",
            " 2374.0823 2382.5068 2387.1367 2360.346  2338.2542 2319.7983 2305.2827\n",
            " 2316.028  2341.6868 2352.6584 2354.6155 2358.1797 2359.148  2342.2915\n",
            " 2303.843  2292.197  2327.9214 2333.3376 2325.4949 2296.9412 2300.027\n",
            " 2326.1748 2344.2063 2361.6968 2370.0647 2395.5542 2398.0146 2413.1118\n",
            " 2422.6465 2427.9863 2442.3198 2443.5032 2427.5632 2424.8955 2442.165\n",
            " 2436.6204 2407.9592 2392.2815 2374.0828 2339.3965 2318.4167 2317.3523\n",
            " 2301.015  2294.2637 2306.0393 2301.2566 2277.3083 2230.413  2226.6213\n",
            " 2208.7324 2162.0369 2173.4893 2152.828  2149.2402 2160.063  2185.5842\n",
            " 2163.8167 2144.9595 2121.558  2124.4492 2120.451  2105.6672 2126.772\n",
            " 2124.773  2136.157  2112.0344 2089.693  2067.4993 2072.9277 2027.0171\n",
            " 2012.7461 2024.0979]\n",
            "\n",
            "Original Values--  [1139.569946 1104.160034 1087.       1096.949951 1106.800049 1124.98999\n",
            " 1118.050049 1130.079956 1110.       1119.98999  1110.839966 1100.900024\n",
            " 1116.       1105.75     1106.949951 1111.300049 1124.900024 1146.98999\n",
            " 1150.060059 1162.48999  1155.719971 1126.72998  1144.449951 1178.26001\n",
            " 1200.64502  1194.51001  1193.380005 1183.300049 1188.810059 1197.349976\n",
            " 1216.       1226.319946 1196.930054 1198.530029 1185.5      1171.540039\n",
            " 1174.900024 1184.099976 1195.319946 1207.47998  1205.939941 1214.98999\n",
            " 1207.890015 1196.       1200.680054 1203.959961 1210.       1218.\n",
            " 1225.       1233.       1239.180054 1235.98999  1250.689941 1264.119995\n",
            " 1264.77002  1269.       1274.       1185.       1188.050049 1167.76001\n",
            " 1173.650024 1166.26001  1180.469971 1172.01001  1159.030029 1163.589966\n",
            " 1141.959961 1137.209961 1117.869995 1164.51001  1168.469971 1144.5\n",
            " 1148.48999  1146.75     1140.5      1147.359985 1134.       1127.52002\n",
            " 1115.540039 1101.290039 1065.5      1042.900024 1051.540039 1044.98999\n",
            " 1050.630005 1072.97998  1093.97998  1078.       1083.640015 1086.420044\n",
            " 1086.280029 1109.689941 1105.599976 1119.98999  1109.23999  1119.609985\n",
            " 1112.660034 1086.5      1084.       1076.390015 1098.       1102.23999\n",
            " 1117.410034 1117.800049 1125.170044 1111.800049 1131.219971 1143.25\n",
            " 1143.98999  1146.859985 1146.       1150.969971 1141.73999  1148.189941\n",
            " 1133.449951 1144.       1131.900024 1137.819946 1224.040039 1241.050049\n",
            " 1225.410034 1223.       1214.030029 1200.73999  1170.040039 1163.310059\n",
            " 1156.       1182.829956 1197.98999  1179.209961 1171.459961 1176.310059\n",
            " 1163.5      1179.550049 1190.089966 1195.25     1193.150024 1194.069946\n",
            " 1181.98999  1157.26001  1180.530029 1161.709961 1181.119995 1198.5\n",
            " 1177.030029 1176.709961 1191.530029 1208.130005 1204.       1195.150024\n",
            " 1203.410034 1224.300049 1231.349976 1229.52002  1230.400024 1227.51001\n",
            " 1232.060059 1233.119995 1226.       1240.       1215.819946 1241.959961\n",
            " 1243.01001  1220.969971 1219.       1196.97998  1180.       1191.890015\n",
            " 1204.400024 1197.589966 1199.349976 1198.579956 1222.209961 1212.339966\n",
            " 1220.400024 1241.170044 1250.930054 1253.459961 1252.26001  1247.849976\n",
            " 1242.359985 1260.900024 1251.030029 1275.449951 1276.22998  1252.969971\n",
            " 1261.280029 1265.       1276.449951 1292.890015 1289.459961 1294.280029\n",
            " 1305.280029 1303.180054 1300.       1294.069946 1297.5      1318.939941\n",
            " 1332.219971 1327.699951 1311.73999  1301.47998  1305.619995 1299.180054\n",
            " 1309.859985 1315.       1307.119995 1301.       1279.569946 1307.01001\n",
            " 1328.       1333.439941 1338.040039 1341.5      1350.839966 1345.939941\n",
            " 1347.949951 1356.5      1362.890015 1356.599976 1351.819946 1363.349976\n",
            " 1355.869995 1348.5      1346.170044 1362.98999  1350.       1330.109985\n",
            " 1341.550049 1347.859985 1350.       1397.939941 1392.079956 1420.569946\n",
            " 1427.560059 1436.130005 1439.01001  1430.209961 1447.439941 1462.910034\n",
            " 1479.119995 1491.       1487.640015 1493.589966 1431.       1443.\n",
            " 1458.800049 1439.959961 1468.900024 1462.       1457.069946 1462.420044\n",
            " 1450.329956 1467.300049 1474.319946 1511.810059 1514.47998  1512.689941\n",
            " 1515.599976 1515.       1525.069946 1522.       1508.030029 1426.109985\n",
            " 1433.       1396.140015 1362.060059 1277.5      1351.609985 1399.420044\n",
            " 1359.22998  1350.199951 1277.060059 1205.300049 1260.       1249.699951\n",
            " 1126.       1179.       1096.       1093.109985 1056.51001  1093.050049\n",
            " 1135.719971 1061.319946 1103.77002  1126.469971 1111.800049 1125.670044\n",
            " 1125.040039 1147.300049 1122.       1098.26001  1119.015015 1138.\n",
            " 1221.       1206.5      1224.079956 1209.180054 1245.089966 1245.609985\n",
            " 1274.099976 1284.849976 1271.       1247.       1245.540039 1271.550049\n",
            " 1261.170044 1296.       1287.930054 1341.459961 1324.880005 1328.5\n",
            " 1308.22998  1337.920044 1361.689941 1365.939941 1383.130005 1378.280029\n",
            " 1407.119995 1377.050049 1335.02002  1350.       1361.75     1386.996948\n",
            " 1389.579956 1408.       1396.709961 1437.27002  1417.25     1396.859985\n",
            " 1416.939941 1418.390015 1430.550049 1438.300049 1430.400024 1413.170044\n",
            " 1422.339966 1445.359985 1459.540039 1442.47998  1428.48999  1390.800049\n",
            " 1445.219971 1447.160034 1449.160034 1444.       1429.       1455.640015\n",
            " 1461.51001  1429.900024 1431.390015 1358.180054 1390.439941 1411.099976\n",
            " 1446.939941 1480.060059 1490.       1494.319946 1506.449951 1506.150024\n",
            " 1550.       1490.310059 1523.130005 1500.       1521.619995 1515.26001\n",
            " 1586.98999  1560.5      1566.969971 1498.930054 1515.599976 1525.180054\n",
            " 1506.319946 1497.       1505.01001  1486.640015 1476.569946 1469.300049\n",
            " 1471.75     1500.       1487.180054 1492.439941 1485.579956 1510.339966\n",
            " 1515.660034 1514.670044 1526.180054 1553.310059 1543.449951 1577.030029\n",
            " 1593.97998  1582.069946 1608.       1653.680054 1633.48999  1647.890015\n",
            " 1636.630005 1673.775024 1709.713989 1624.26001  1533.51001  1557.530029\n",
            " 1560.640015 1536.       1539.005005 1536.       1555.540039 1496.\n",
            " 1498.01001  1440.060059 1450.089966 1458.780029 1411.030029 1432.630005\n",
            " 1474.209961 1470.390015 1466.800049 1484.27002  1462.030029 1466.209961\n",
            " 1475.579956 1464.290039 1465.089966 1494.699951 1543.       1583.72998\n",
            " 1578.589966 1547.150024 1565.849976 1580.459961 1527.050049 1573.329956\n",
            " 1593.050049 1626.069946 1625.01001  1595.670044 1559.73999  1522.359985\n",
            " 1672.109985 1628.160034 1631.780029 1710.280029 1781.       1753.949951\n",
            " 1790.900024 1731.089966 1750.       1747.630005 1757.630005 1771.699951\n",
            " 1776.939941 1765.22998  1738.380005 1765.209961 1749.599976 1730.5\n",
            " 1772.890015 1773.089966 1781.18396  1774.369995 1798.099976 1824.01001\n",
            " 1824.52002  1819.       1810.099976 1812.01001  1769.800049 1763.060059\n",
            " 1775.       1764.420044 1772.880005 1768.51001  1754.180054 1713.51001\n",
            " 1734.430054 1728.109985 1735.       1751.63501  1787.790039 1762.01001\n",
            " 1735.420044 1757.540039 1725.       1702.630005 1740.060059 1787.97998\n",
            " 1786.069946 1753.920044 1738.579956 1753.619995 1738.189941 1752.25\n",
            " 1831.459961 1898.       1895.680054 1920.670044 1888.839966 1882.530029\n",
            " 1843.939941 1846.170044 1853.569946 1922.560059 2073.       2068.889893\n",
            " 2070.       2105.909912 2078.540039 2094.209961 2099.51001  2090.25\n",
            " 2104.360107 2100.       2110.389893 2119.27002  2067.       2025.01001\n",
            " 2041.829956 2067.449951 2050.52002  2056.52002  2076.189941 2067.209961\n",
            " 2023.369995 2073.120117 2101.129883 2070.       2071.76001  2074.060059\n",
            " 2085.       2062.300049 2078.98999  2076.030029 2061.       2042.050049\n",
            " 2041.839966 2051.699951 2065.370117 2044.810059 2038.859985 2027.880005\n",
            " 2057.629883 2059.120117 2097.949951 2152.939941 2222.5      2226.129883\n",
            " 2277.959961 2256.699951 2266.25     2261.469971 2275.159912 2276.97998\n",
            " 2303.       2291.97998  2307.889893 2285.25     2293.22998  2283.469971\n",
            " 2319.929932 2336.       2407.14502  2410.330078 2404.48999  2402.719971\n",
            " 2369.73999  2368.419922 2350.639893 2400.       2374.889893 2291.860107\n",
            " 2261.709961 2261.090088 2291.830078 2309.320068 2336.906006 2264.399902\n",
            " 2328.040039 2365.98999  2367.       2420.       2412.834961 2436.939941\n",
            " 2421.959961 2422.       2435.310059 2395.02002  2422.52002  2451.320068\n",
            " 2479.899902 2499.5      2494.01001  2524.919922 2513.389893 2530.439941\n",
            " 2524.949951 2510.459961 2514.110107 2514.800049 2529.       2531.\n",
            " 2541.070068 2539.139893 2540.       2535.449951 2513.071045 2496.995117\n",
            " 2536.790039 2588.98999  2606.820068 2565.       2578.889893 2596.669922\n",
            " 2617.629883 2638.030029 2650.       2632.820068 2623.110107 2600.080078\n",
            " 2615.73999  2653.       2705.199951 2765.       2800.219971 2771.23999\n",
            " 2727.612061 2710.219971 2709.689941 2720.       2724.98999  2720.570068\n",
            " 2725.899902 2738.97998  2761.590088 2765.659912 2754.26001  2767.149902\n",
            " 2760.       2763.820068 2742.310059 2709.350098 2741.659912 2779.969971\n",
            " 2830.870117 2857.659912 2852.370117 2842.25     2894.090088 2917.689941\n",
            " 2913.       2918.98999  2882.919922 2894.98999  2907.870117 2897.669922\n",
            " 2908.870117 2864.02002  2883.219971 2875.179932 2902.419922 2875.969971\n",
            " 2780.003906 2802.340088 2801.01001  2832.189941 2818.919922 2831.709961\n",
            " 2781.77002  2742.194092 2686.5      2671.090088 2713.98999  2680.\n",
            " 2692.51001  2777.26001  2798.120117 2796.       2792.75     2755.\n",
            " 2799.040039 2844.       2824.27002  2865.830078 2884.449951 2843.840088\n",
            " 2807.02002  2776.209961 2812.120117 2798.050049 2945.97998  2910.399902\n",
            " 2963.300049 2896.187988 2925.5      2944.       2987.070068 3000.\n",
            " 2994.919922 2960.195068 2942.139893 2956.629883 3000.       2983.409912\n",
            " 2984.580078 2982.919922 3020.       3002.834961 2942.26001  2927.\n",
            " 2900.310059 2885.969971 2909.004883 2884.25     2836.47998  2889.909912\n",
            " 2871.47998  2919.       2966.629883 2963.52002  2982.       2968.879883\n",
            " 2895.399902 2887.320068 2961.540039 2854.290039 2813.592041 2863.\n",
            " 2882.       2941.790039 2949.27002  2967.48999  2928.590088 2929.\n",
            " 2910.879883 2889.51001  2911.01001  2883.620117 2749.949951 2758.100098\n",
            " 2701.97998  2763.610107 2831.090088 2836.810059 2750.       2732.\n",
            " 2738.77002  2730.280029 2660.23999  2520.550049 2568.709961 2611.850098\n",
            " 2627.219971 2600.       2683.959961 2756.699951 3037.27002  2905.899902\n",
            " 2860.340088 2874.179932 2779.824951 2816.995117 2790.       2775.\n",
            " 2667.310059 2749.429932 2728.610107 2723.       2660.75     2599.699951\n",
            " 2621.570068 2500.       2670.51001  2665.689941 2689.600098 2692.165039\n",
            " 2719.570068 2667.649902 2638.080078 2525.01001  2628.       2629.25\n",
            " 2679.98999  2611.459961 2554.830078 2620.       2666.419922 2677.679932\n",
            " 2736.949951 2730.       2782.77002  2785.449951 2835.080078 2813.689941\n",
            " 2863.209961 2857.399902 2848.969971 2800.199951 2816.48999  2867.98999\n",
            " 2783.22998  2732.360107 2725.       2658.       2648.469971 2572.530029\n",
            " 2612.98999  2548.199951 2561.540039 2625.679932 2587.       2500.\n",
            " 2388.590088 2455.       2287.459961 2342.300049 2351.560059 2278.129883\n",
            " 2335.300049 2360.070068 2404.409912 2310.379883 2266.070068 2320.810059\n",
            " 2274.209961 2238.76001  2296.909912 2307.679932 2344.550049 2304.75\n",
            " 2236.820068 2241.709961 2202.080078 2127.550049 2102.840088 2121.01001\n",
            " 2195.77002 ]\n"
          ]
        }
      ],
      "source": [
        "print(\"Pred Values-- \" ,pred)\n",
        "print(\"\\nOriginal Values-- \",original)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "eLF5HUHs9r6d",
        "outputId": "6d6c4137-8595-4805-88db-87e78374e92e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#plt.xlim([100,500])\n",
        "plt.plot(original, color = 'red', label = 'Real  Stock Price')\n",
        "plt.plot(pred, color = 'blue', label = 'Predicted  Stock Price')\n",
        "plt.title(' Stock Price Prediction')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel(' Stock Price')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "LSTM AND GRU.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}